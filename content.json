{"meta":{"title":"Japan Machine Learning Support Blog","subtitle":"","description":"","author":"jpmlblog","url":"https://jpmlblog.github.io/blog","root":"/blog/"},"pages":[],"posts":[{"title":"v2 API の有効化に伴う Azure Machine Learning Workspace への影響について","slug":"AML_available-using-the-v2-API","date":"2022-05-17T15:00:00.000Z","updated":"2022-05-18T08:23:08.878Z","comments":true,"path":"2022/05/18/AML_available-using-the-v2-API/","link":"","permalink":"https://jpmlblog.github.io/blog/2022/05/18/AML_available-using-the-v2-API/","excerpt":"件名 「Network Isolation Change with Our New API Platform on Azure Resource Manager」 の電子メールにて、Action Required to use new API platform with private link enabled workspace といった内容が通知されています。 このメールにおいて実際に必要な対応内容をお纏めして紹介します。 (注意) 本情報は適宜調整しております。併せて下記公式サイトをご参照ください。 Network Isolation Change with Our New API Platform on Azure Resource Manager","text":"件名 「Network Isolation Change with Our New API Platform on Azure Resource Manager」 の電子メールにて、Action Required to use new API platform with private link enabled workspace といった内容が通知されています。 このメールにおいて実際に必要な対応内容をお纏めして紹介します。 (注意) 本情報は適宜調整しております。併せて下記公式サイトをご参照ください。 Network Isolation Change with Our New API Platform on Azure Resource Manager v2 API とはAzure Machine Learning サービスで使用される API は、ARM 宛に要求を発行するもの、ワークスペース リソース宛に要求を発行するものの 2 種類が存在します。 これまでの API (v1 API) は、ワークスペースやコンピューティング リソースに対する操作以外は基本的にワークスペース宛に要求を送っていました。 新しい API (v2 API) では、それらの多くが ARM 宛に要求を送る様に変更されます。 API&nbsp;&nbsp;&nbsp;&nbsp; Public ARM 宛の操作 Workspace 宛の操作 v1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ワークスペースおよびコンピューティング リソースの作成、更新、削除操作 実験などその他の操作 v2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ワークスペース、コンピューティング、データストア、データセット、ジョブ、環境、コード、コンポーネント、エンドポイントなど 残りの操作 v2 API を使用することで、RBAC を使用したアクセス制御や Azure Policy の適用が使い易くなる見込みです。 また、Azure Machine Learning のマネージド オンライン エンドポイントなどの新機能は v2 API でしか使用できないため、これらが利用できるといったメリットもあります。 v2 API によって発生するネットワーク分離への影響について前項で述べたように、API 操作には ARM を使用するものとワークスペースを使用するものがあり、v2 になることでその多くが ARM を使用するように変更されます。 プライベート エンドポイントを持たないワークスペースでは、ARM 宛とワークペース宛のいずれもパブリック ネットワークを経由して通信を行っているため、影響はありません。 プライベート エンドポイントを持つワークスペースでは、ワークスペース宛の通信は仮想ネットワーク内に閉じた通信になっていましたが、ARM 宛となることでほとんどの操作がパブリック ネットワーク経由となります。 Azure のサービスから発信する ARM 宛の通信は、基本的に Azure Global Network 内には閉じています。 また、送信される情報はメタデータ (リソース ID など) やパラメータです。 例えば、ジョブの作成や更新 で送信されるのは パラメータ のみとなります。 ストレージ アカウント上の情報が含まれることは無く、また TLS 1.2 を使用して暗号化されているため読み取られる危険も低いです。 基本的にこの変更がセキュリティに影響をあたえることは無いものと考えていますが、プライベート エンドポイントを持つ “既存の” ワークスペースについては影響の有無の判断の時間を設けるため、v1_legacy_mode パラメーターを用意し、予め True がセットされています。 これにより、v1 API の操作が継続されます。 なお、v2 API を使用する場合には v1_legacy_mode パラメーターを False にセットする必要があります。 ※ プライベート エンドポイントを持たない “既存の” ワークスペースは v1_legacy_mode パラメーターはセットされません (v2 API が使用される設定になります)。 v1_legacy_mode パラメーターの設定値について基本的に v1_legacy_mode パラメーターの設定条件は以下の通りです。 各シナリオとは異なるバージョンの API を使用したい場合には、後述の手順で変更ください。 2022/5/1 以前に作成されたワークスペースの場合 プライベート エンドポイントを持つ “既存の” ワークスペースでは v1_legacy_mode パラメーターに True がセット ⇒ v1 API プライベート エンドポイントを持たない “既存の” ワークスペースでは v1_legacy_mode パラメーターはセットされない ⇒ v2 API 2022/5/1 以降に作成されたワークスペースの場合 プライベート エンドポイントを持つ “既存の” ワークスペースでは v1_legacy_mode パラメーターに True がセット ⇒ v1 API プライベート エンドポイントを持たない “既存の” ワークスペースでは v1_legacy_mode パラメーターに False がセット ⇒ v2 API 新しく作成するワークスペースは v1_legacy_mode パラメーターに False がセット ⇒ v2 API v1_legacy_mode パラメーターの確認・更新方法についてAzure Machine Learning 用の CLI 拡張機能 v1 (azure-cli-ml) を使用する方法が簡単です。 確認方法 1az ml workspace show -g &lt;myresourcegroup&gt; -w &lt;myworkspace&gt; --query v1LegacyMode 更新方法 1az ml workspace update -g &lt;myresourcegroup&gt; -w &lt;myworkspace&gt; --v1-legacy-mode &lt;true or false&gt; SDK で更新する場合には、以下のコードを実行することで更新が可能ですが、2022/5/1 以前に作成されたワークスペースでは実行がエラーになる場合があるため、CLI 拡張機能の使用をお勧めします。 更新方法1234from azureml.core import Workspacews = Workspace.from_config()ws.update(v1_legacy_mode=false) 変更履歴2022/05/18 created by Mochizuki ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"v2 API","slug":"v2-API","permalink":"https://jpmlblog.github.io/blog/tags/v2-API/"},{"name":"Private Endpoint","slug":"Private-Endpoint","permalink":"https://jpmlblog.github.io/blog/tags/Private-Endpoint/"}]},{"title":"Azure Machine Learning パイプラインを使用した自動機械学習ライフサイクルの例","slug":"AML_example_pipeline_lifecycle","date":"2021-10-20T15:00:00.000Z","updated":"2022-05-18T08:23:08.885Z","comments":true,"path":"2021/10/21/AML_example_pipeline_lifecycle/","link":"","permalink":"https://jpmlblog.github.io/blog/2021/10/21/AML_example_pipeline_lifecycle/","excerpt":"Azure Machine Learning のライフサイクルを実現する Azure Machine Learning パイプラインの利用例について紹介させていただきます。今回紹介するライフサイクルは次の通りです。 ストレージ アカウント上の csv ファイル読み込み 自動機械学習を実行 ベスト モデルを選択して ACI にデプロイ","text":"Azure Machine Learning のライフサイクルを実現する Azure Machine Learning パイプラインの利用例について紹介させていただきます。今回紹介するライフサイクルは次の通りです。 ストレージ アカウント上の csv ファイル読み込み 自動機械学習を実行 ベスト モデルを選択して ACI にデプロイ イメージ// ライフサイクルは以下のようなイメージです。これを参考に後述の手順をご確認ください。 パイプラインの作成以下の図のように、データセットを入力として自動機械学習を実行し、作成されたモデルを登録、ACI Web エンドポイントを作成または更新するパイプラインを作成します。パイプラインの作成は、ノートブック ファイルの実行により行います。実行するノートブック ファイルと、使用するデータを以下リンクからダウンロードください。 aml-pipeline-sample_1.ipynb machineData.csv // 上記ファイルを使って以下のような処理を行うパイプラインを作成します。 データの配置ダウンロードした machineData.csv ファイルを、Azure Machine Learning ワークスペースの既定のストレージ アカウントのコンテナー azureml-blobstore-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx (xxx 部分はランダムな英数字) 配下に Datasets フォルダーを作成し、アップロードしておきます。 ノートブックの実行aml-pipeline-sample_1.ipynb ファイルは、以下の通り Azure Machine Learning Studio の Notebooks のフォルダーにアップロードし、[カーネルを再起動し、すべてのセルを実行する] をクリックします。(実行時に cpu-cluster という名前の STANDARD_DS12_V2 のコンピューティング クラスターが作成されます。既に存在する場合はそのコンピューティング クラスターを使用します。) パイプラインの公開実行が終了すると、以下の通りエンドポイントとパイプラインが作成されるため、正常に実行が終了していることを確認して [公開] ボタンをクリックし、任意の名前で実行します。実行後、パイプライン エンドポイントが作成されます。(サンプル では pipeline_with_automlstep という名前になります。) // 自動機械学習によって作成されたモデルをデプロイしたリアルタイム エンドポイント // ノートブックで定義したパイプラインの実行結果 (この画面で [公開] ボタンを押す) // 外部から呼び出せるように公開されたパイプラインのエンドポイント パイプラインの使用公開したパイプライン エンドポイントの REST エンドポイントに対し、POST メソッドで要求を送信するとパイプラインを実行されます。これにより、azureml-blobstore-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx (xxx 部分はランダムな英数字) / Datasets フォルダー配下の machineData.csv ファイルを新しいファイルに変更してパイプラインを実行するだけで、新しいファイルを使用した自動機械学習、モデルの登録、ACI エンドポイントの作成を簡単に行うことが可能になります。 // REST エンドポイントは、公開されたパイプラインの概要ページより確認できます。 REST エンドポイントへの要求送信方法は多種ありますが、後述に Python および PowherShell を使用した実行方法を紹介させていただきます。 Python での実行下記コードの &lt;公開したパイプラインの REST エンドポイント&gt; を上述の REST エンドポイント URL に置き換えて Notebook 上から実行するだけで、パイプラインをトリガーすることが可能です。 json 形式で実験名やパイプライン パラメーターを引数として渡すことが可能です。ただし、primary_metric は作りこみは不十分なので、変更する際には aml-pipeline-sample_1.ipynb ファイル側のロジックも含めて変更をご検討ください。 ExperimentName: 実験の名前 model_name: 登録されるモデルの名前 primary_metric: 自動機械学習のプライマリ メトリック aciservice_name: ACI エンドポイントの名前 12345678910111213from azureml.core.authentication import InteractiveLoginAuthenticationimport requestsauth = InteractiveLoginAuthentication()aad_token = auth.get_authentication_header()response = requests.post(&quot;&lt;公開したパイプラインの REST エンドポイント&gt;&quot;, headers=aad_token, json=&#123;&quot;ExperimentName&quot;: &quot;pipeline-cycle-test&quot;, &quot;ParameterAssignments&quot;: &#123;&quot;model_name&quot;: &quot;automlmodel&quot;, &quot;primary_metric&quot;: &quot;r2_score&quot;, &quot;aciservice_name&quot;: &quot;aciservice&quot;&#125;&#125;) PowerShell での実行下記コマンドの &lt;公開したパイプラインの REST エンドポイント&gt; を上述の REST エンドポイント URL に置き換えて PowerShell コマンド プロンプト上で実行するだけで、パイプラインをトリガーすることが可能です。 $postText で実験名やパイプライン パラメーターを引数として渡すことが可能です。Python での実行と同じように primary_metric を変更する際には aml-pipeline-sample_1.ipynb ファイル側のロジックも含めて変更をご検討ください。 ExperimentName: 実験の名前 model_name: 登録されるモデルの名前 primary_metric: 自動機械学習のプライマリ メトリック aciservice_name: ACI エンドポイントの名前 123456789101112131415161718az login$aad_token = az account get-access-token$convert_token = $aad_token | ConvertFrom-Json$parsed_token = &quot;Bearer &quot;+$convert_token.accessToken$requestUri = &quot;&lt;公開したパイプラインの REST エンドポイント&gt;&quot; $requestHeader = @&#123; &#x27;Content-type&#x27;=&#x27;application/json&#x27; &#x27;authorization&#x27; = $parsed_token&#125; $postText = &quot;&#123;&quot;&quot;ExperimentName&quot;&quot;: &quot;&quot;pipeline-cycle-test&quot;&quot;,&quot;&quot;ParameterAssignments&quot;&quot;: &#123;&quot;&quot;model_name&quot;&quot;: &quot;&quot;automlmldel&quot;&quot;, &quot;&quot;primary_metric&quot;&quot;: &quot;&quot;r2_score&quot;&quot;, &quot;&quot;aciservice_name&quot;&quot;: &quot;&quot;aciservice&quot;&quot;&#125;&#125;&quot;$postBody = [Text.Encoding]::UTF8.GetBytes($postText)Invoke-RestMethod -Method POST -Uri $requestUri -Headers $requestHeader -Body $postBody サービス プリンシパルを使用すると、ワークスペースに対してアクセス権のないユーザーでもパイプラインを実行できるようになります。まず、下記サイトの手順に従いアプリケーションの登録を行い、ワークスペース リソースに “共同作成者 (Contributor)” ロールを付与します。 Authentication in Azure Machine Learning ※ Service Principal Authentication セクションを参照ください。 上述のコマンドのうち 1 行目を以下の通り変更して実行ください。 1az login --service-principal -u &quot;&lt;アプリケーション (クライアント) ID&gt;&quot; -p &quot;&lt;クライアント シークレット&gt;&quot; --tenant &quot;&lt;ディレクトリ (テナント) ID&gt;&quot; 変更履歴2021/10/21 created by Mochizuki2021/11/19 modified by Mochizuki ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"パイプライン","slug":"パイプライン","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3/"},{"name":"ライフサイクル","slug":"ライフサイクル","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%A9%E3%82%A4%E3%83%95%E3%82%B5%E3%82%A4%E3%82%AF%E3%83%AB/"}]},{"title":"名前に日本語を含むリソースグループを使用する場合の注意点について","slug":"AML-resourcegroup-name","date":"2021-10-15T15:00:00.000Z","updated":"2022-05-18T08:23:09.012Z","comments":true,"path":"2021/10/16/AML-resourcegroup-name/","link":"","permalink":"https://jpmlblog.github.io/blog/2021/10/16/AML-resourcegroup-name/","excerpt":"リソースグループ名に日本語 (例: 機械学習用リソースグループ) など 2 バイト文字が含まれる場合、当該リソースグループに Azure Machine Learning ワークスペースを作るといくつかの管理操作がエラーとなる場合がございます。これらの事例と、推奨する設定をお纏めいたします。","text":"リソースグループ名に日本語 (例: 機械学習用リソースグループ) など 2 バイト文字が含まれる場合、当該リソースグループに Azure Machine Learning ワークスペースを作るといくつかの管理操作がエラーとなる場合がございます。これらの事例と、推奨する設定をお纏めいたします。 確認できている事象について日本語を含んだ名前のリソースグループを使用する場合、コントロール プレーン操作 (管理操作) や一部の UI 機能の実行がエラーとなることを確認しております。これは、操作の実行時に行われる認証処理など内部通信において、日本語を含むリソース ID を正しく認識できないことに起因して発生いたします。 現在 (2021/11/08)、確認できている事象は以下の通りです。 自動機械学習の DNN オプションを使用できない (※ 2021/10/19 修正済み) コンピューティング インスタンス起動 / 停止が失敗する (※ 2021/11/08 修正済み) コンピューティング インスタンスのスケジュール起動 / 停止が動作しない また、ノートブックで Python コードを実行する際、こうしたリソース ID が使用されるような処理においても失敗する可能性がございます。オープンソースのモジュールで日本語など 2 バイト文字に対応していない場合、弊社にて修正および回避策を提示できない場合もございます。 推奨する設定についてAzure Machine Learning サービスに閉じた機能であれば修正リクエストをいただくことで適宜対処を検討させていただくことは可能ですが、対処の完了まで時間がかかる場合があり、また別のサービスとの連携を含む機能では修正が困難となる可能性もございます。上記を踏まえまして、リソースグループ名は 「英数字およびハイフンのみ」 としていただくことを強く推奨いたします。 ※ ワークスペースおよびコンピューティング リソースに関する名前付け制限は以下をご参照ください。 Azure リソースの名前付け規則と制限事項 #Microsoft.MachineLearningServices Entity Scope 長さ 有効な文字 workspaces&nbsp;&nbsp;&nbsp; resource group&nbsp;&nbsp;&nbsp; 3-33&nbsp;&nbsp;&nbsp; 英数字とハイフン。 workspaces / computes&nbsp;&nbsp;&nbsp; ワークスペース&nbsp;&nbsp;&nbsp; 2-16&nbsp;&nbsp;&nbsp; 英数字とハイフン。 変更履歴2021/10/16 created by Mochizuki2021/10/19 modified by Mochizuki2021/11/08 modified by Mochizuki ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"日本語","slug":"日本語","permalink":"https://jpmlblog.github.io/blog/tags/%E6%97%A5%E6%9C%AC%E8%AA%9E/"},{"name":"リソースグループ","slug":"リソースグループ","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%B0%E3%83%AB%E3%83%BC%E3%83%97/"},{"name":"コンピューティング インスタンス","slug":"コンピューティング-インスタンス","permalink":"https://jpmlblog.github.io/blog/tags/%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0-%E3%82%A4%E3%83%B3%E3%82%B9%E3%82%BF%E3%83%B3%E3%82%B9/"}]},{"title":"Azure Machine Learning Studio (classic) のサービス終了について","slug":"AMLSC-service-retirement","date":"2021-08-24T15:00:00.000Z","updated":"2022-05-18T08:23:09.048Z","comments":true,"path":"2021/08/25/AMLSC-service-retirement/","link":"","permalink":"https://jpmlblog.github.io/blog/2021/08/25/AMLSC-service-retirement/","excerpt":"Azure Machine Learning Studio (classic) は、2024 年 8 月 31 日を持ちましてサービスを終了いたします。関連する公開情報や留意事項についてご紹介させていただきます。 Machine Learning Studio (classic) will retire on 31 August 2024","text":"Azure Machine Learning Studio (classic) は、2024 年 8 月 31 日を持ちましてサービスを終了いたします。関連する公開情報や留意事項についてご紹介させていただきます。 Machine Learning Studio (classic) will retire on 31 August 2024 サービス終了までの段階的制限 日時 サービスの制限 2021 年 8 月 24 日以降&nbsp;&nbsp;&nbsp; 公開ドキュメント・不具合等の修正は基本的に対応不可 2021 年 12 月 1 日以降&nbsp;&nbsp;&nbsp; 新規リソースの作成不可 2024 年 8 月 31 日以降&nbsp;&nbsp;&nbsp; リソース使用不可 ※ 影響の大きな不具合は修正される可能性があります。 対象リソース Azure Machine Learning Studio (classic) workspaces Azure Machine Learning Studio (classic) Web services Azure Machine Learning Studio (classic) Web service plans ※ Azure ポータルの言語設定が日本語の場合、”(classic)” が省略されております。 移行方法移行に関する手順は以下公開情報に纏められております。当該ドキュメントは今後更新される可能性がございますので、適宜ご参照ください。 Migrate to Azure Machine Learning 基本的に、Azure Machine Learning Studio (classic) で使用していた機能を、移行先サービス Azure Machine Learning Service で再作成する方針となります。ボタン一つでまとめて移行できるようなものではないため、期間的に十分な余裕をもって実行いただくことをお勧めいたします。 移行先のサービスとの比較に関する情報は下記公開情報に纏められております。ML Studio (classic) と Azure Machine Learning スタジオ 留意事項ワークスペースに関連付けされている Web service plans リソースを先に削除したり、そのほか予期しない操作によってリソースの削除が完全に行われず、課金が継続して発生してしまうといったお問い合わせが複数件報告されています。 リソースを削除後、課金情報にリソース プロバイダー “Microsoft.MachineLearning” に関する料金が継続して累積されている場合には、以下記事の情報を参考にサポート リクエストを発行いただきますようお願いいたします。 Azure Machine Learning Studio (Classic) ワークスペースを削除できない事象について 変更履歴2021/08/25 created by Mochizuki ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning Studio (classic)","slug":"Azure-Machine-Learning-Studio-classic","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning-Studio-classic/"}],"tags":[{"name":"サービス終了","slug":"サービス終了","permalink":"https://jpmlblog.github.io/blog/tags/%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E7%B5%82%E4%BA%86/"}]},{"title":"Azure Machine Learning Studio で参照可能なデータの格納場所について","slug":"AML-storage-data-location","date":"2021-06-15T15:00:00.000Z","updated":"2022-05-18T08:23:09.053Z","comments":true,"path":"2021/06/16/AML-storage-data-location/","link":"","permalink":"https://jpmlblog.github.io/blog/2021/06/16/AML-storage-data-location/","excerpt":"Azure Machine Learning Studio で作成した実験用ノートブック ファイルやスクリプト、実験時のログ、アップロードしたファイルなどは、Azure Machine Learning ワークスペース既定のストレージ アカウントに格納されます。お問い合わせをいただくことが多い格納先について紹介します。","text":"Azure Machine Learning Studio で作成した実験用ノートブック ファイルやスクリプト、実験時のログ、アップロードしたファイルなどは、Azure Machine Learning ワークスペース既定のストレージ アカウントに格納されます。お問い合わせをいただくことが多い格納先について紹介します。 Notebooks メニューから参照可能なファイルAzure Machine Learning Studio の [Notebooks] メニューより参照可能なファイルやフォルダーは、ワークスペースが既定で使用するストレージ アカウントの [ファイル共有] の code-&lt;GUID&gt;/Users 配下に格納されます。 また、このファイル共有はコンピューティング インスタンスにログオンした時に、/mnt/batch/tasks/shared/LS_root/mounts/clusters/&#123;コンピューティング インスタンス名&#125;/code というパスに自動でマウントされます。 例: Azure Machine Learning Studio の [Notebooks] メニューのフォルダー ツリー 例: ストレージ アカウントの [ファイル共有] code-&lt;GUID&gt;/Users 配下 例: コンピューティング インスタンスの /mnt/batch/tasks/shared/LS_root/mounts/clusters/&#123;コンピューティング インスタンス名&#125;/code 配下 実験の成果物Azure Machine Learning Studio の [実験] メニューより参照可能な成果物 (ログ ファイルやモデル ファイル等) は、ワークスペースが既定で使用するストレージ アカウントの [Blob コンテナー] の azureml/ExperimentRun/dcid.&lt;実行 ID&gt; 配下に格納されます。 例: Azure Machine Learning Studio の [実験] メニューの [詳細] タブ 例: Azure Machine Learning Studio の [実験] メニューの [出力とログ] タブ 例: ストレージ アカウントの [Blob コンテナー] azureml/ExperimentRun/dcid.&lt;実行 ID&gt; 配下 ※ 適宜追加予定です。 変更履歴2021/6/16 created by Mochizuki ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"Blob コンテナー","slug":"Blob-コンテナー","permalink":"https://jpmlblog.github.io/blog/tags/Blob-%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E3%83%BC/"},{"name":"ファイル共有","slug":"ファイル共有","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%85%B1%E6%9C%89/"}]},{"title":"Azure MachineLeaning Studio の Notebooks メニューにおける「現時点ではこれにはアクセスできません」エラーへの対応方法","slug":"AML-cannot-use-notebook","date":"2021-03-28T15:00:00.000Z","updated":"2022-05-18T08:23:08.893Z","comments":true,"path":"2021/03/29/AML-cannot-use-notebook/","link":"","permalink":"https://jpmlblog.github.io/blog/2021/03/29/AML-cannot-use-notebook/","excerpt":"本記事では、Azure MachineLeaning Studio の Notebooks メニューで開いた Notebook で処理を実行した際に「現時点ではこれにはアクセスできません」とエラーメッセージが表示されてしまう場合の対応方法をご案内します。","text":"本記事では、Azure MachineLeaning Studio の Notebooks メニューで開いた Notebook で処理を実行した際に「現時点ではこれにはアクセスできません」とエラーメッセージが表示されてしまう場合の対応方法をご案内します。 対応方法Azure MachineLeaning Studio の Compute メニュー利用による回避Azure MachineLeaning Studio（以下 AML Studio） の Notebooks メニュー使用時に、権限に関するエラーが表示される場合があります。 原因は Azure Active Directory 側の設定に依存する可能性がありますが、コンピューティング メニュー のアプリケーション URI 配下のメニューから Notebook を開き直す対応で、問題が解消する場合があります。 Notebooks メニューと コンピューティング メニューにおいてはそれぞれのバックエンドの認証方法が異なります。そのため、コンピューティング メニューから Notebook を実行した場合には、AML Studio への認証情報がコンピューティングインスタンスに連携されて権限エラーが生じない可能性があります。 なお、AML Studio を通じて配置された Notebook などのファイルが存在する階層の実体は、AMLワークスペース既定のストレージアカウントです。 （コンピューティングインスタンス内部から参照した際のパス例： /mnt/batch/tasks/shared/LS_root/mounts/clusters/{コンピューティングインスタンス名}/code/Users/{ユーザー名}） そのため、Notebooksメニューと コンピューティング メニューのどちらのメニューを通じた利用でも、ファイルの数や内容は同じです。もし、コンピューティング メニューの利用で問題が解消する場合には、こちらの回避策の利用のご検討をいただければ幸いです。 もし、コンピューティング メニュー利用による問題の回避が行えない場合には、次項の「Azure Active Directory へのネームドロケーションの登録追加」対応をご検討ください。 Azure Active Directory へのネームドロケーションの登録追加「アクセスできません」というエラーの権限の問題の根本的な対応として、テナント（Azure Active Directory）管理者様により、該当するコンピューティング インスタンスのIPアドレスをネームドロケーションとして追加登録していただくことで、問題が解消される可能性があります。 - クイック スタート:Azure Active Directory でネームド ロケーションを構成する ネームド ロケーションを使うと、組織内の信頼できる IP アドレス範囲にラベルを付けることができます。Azure AD では、次のためにネームド ロケーションを使用します。 ・リスク検出で誤判定を検出する。 信頼できる場所からサインインすることで、ユーザーのサインイン リスクが低下します。 ・場所ベースの条件付きアクセスを構成する。このクイック スタートでは、環境内でネームド ロケーションを構成する方法について説明します。 追加登録対象となるコンピューティングインスタンスのIPアドレスは、AMLスタジオ の Compute メニューで確認可能です。 エラーメッセージが表示される原因「条件付きアクセス」の設定コンピューティングインスタンスが不詳なデバイスとして認識され、組織データである Azure ML ワークスペースへのアクセスが叶わないことが、エラーの原因となっている可能性があります。「条件付きアクセス」の設定については、弊社 Azure Active Directory サポートチームがブログ記事に詳細を記載しています。 - Japan Azure Identity Support Blog-「現時点ではこれにはアクセスできません」 エラーについて これは Azure Machine Learning の設定ではなく、テナント（Azure Active Directory）管理者による設定です。そのため、まずはテナント管理者様に設定条件をご確認いただく必要があります。 変更履歴2021/03/29 created by Uehara ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"Notebook","slug":"Notebook","permalink":"https://jpmlblog.github.io/blog/tags/Notebook/"},{"name":"権限","slug":"権限","permalink":"https://jpmlblog.github.io/blog/tags/%E6%A8%A9%E9%99%90/"}]},{"title":"Azure Machine Learning で作成したモデルの推論を実行する方法について","slug":"AML-model-inference","date":"2021-01-13T03:00:00.000Z","updated":"2022-05-18T08:23:08.990Z","comments":true,"path":"2021/01/13/AML-model-inference/","link":"","permalink":"https://jpmlblog.github.io/blog/2021/01/13/AML-model-inference/","excerpt":"本記事では、Azure Machne Learning で作成したモデルを SDK を使用して推論実行する方法を紹介します。試験的に作成したモデルの評価を行う場合には、都度 Web サービスにデプロイする方法は効率的ではないため、ローカルにロードして推論実行する手順を紹介します。また、Web サービスにデプロイして推論を実行する方法についても併せて紹介します。","text":"本記事では、Azure Machne Learning で作成したモデルを SDK を使用して推論実行する方法を紹介します。試験的に作成したモデルの評価を行う場合には、都度 Web サービスにデプロイする方法は効率的ではないため、ローカルにロードして推論実行する手順を紹介します。また、Web サービスにデプロイして推論を実行する方法についても併せて紹介します。 ローカルにモデルをロードして評価を行う場合実験によって作成されたモデルのテストを行う場合、ローカル環境にロードして実行する方法をお勧めいたします。以下に、自動機械学習のチュートリアルの実行によって作成されたモデルを例にご紹介いたします。 チュートリアル:Azure Machine Learning の自動 ML で分類モデルを作成する 自動機械学習では、複数のアルゴリズムと前処理の組み合わせを試し、それぞれの実行でモデルを作成します。上記チュートリアルのとおりに実行すると、「my-1st-automl-experiment」 という名前の実験の中で、複数のモデルが作成されます。このうちひとつのモデルをローカルにロードして、推論実行する方法を紹介します。 モデルは、VotingEnsemble を選択します。 「詳細」 タブより実行 ID を確認します。 Notebooks メニューより任意のフォルダーに新しいノートブックを作成し、以下のコードを入力、実行します。experiment_name や run_id は、ご利用環境に合わせて適宜変更ください。 123456789101112# 実行 ID より Run オブジェクトを作成します。from azureml.core import Experiment, Workspacefrom azureml.core.experiment import Experimentfrom azureml.core.run import Runworkspace = Workspace.from_config()experiment_name = &quot;my-1st-automl-experiment&quot;experiment = Experiment(workspace, experiment_name)run = Run(experiment=experiment, run_id=&#x27;AutoML_66d0eb73-e09c-435d-ae80-da060d204b09_69&#x27;)# モデル等の情報を download フォルダー配下に格納します。run.download_files(output_directory=&#x27;download&#x27;) 123456# ダウンロードしたモデルをローカルにロードします。import joblibfrom azureml.core.model import Modelmodel_path = &#x27;download/outputs/model.pkl&#x27;model = joblib.load(model_path) 推論のテストに使用するデータは、トレーニング データに含まれていないものをご用意頂く必要があります。今回は既に用意されているテスト データを使用しますが、一般的にはトレーニング用に収集したデータの 1 割程度をテスト用に分割しておくことをお勧めします。 12345# チュートリアルのテスト用データをデータセットとして読み込みます。from azureml.core.dataset import Datasettest_data = &quot;https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_test.csv&quot;test_dataset = Dataset.Tabular.from_delimited_files(test_data) 既存のデータセットを使用する場合、上記コード セルを以下に変更します。 12345&gt;# 既存のデータセットを読み込みます。&gt;from azureml.core.dataset import Dataset&gt;# detaset_name をデータセット名に置き換えて実行します。&gt;test_dataset = Dataset.get_by_name(workspace, &gt;name=&#x27;bankmarketing_test&#x27;) 1234567# y 列を削除して pandas のデータフレーム形式に変換します。test = test_dataset.drop_columns(columns=[&#x27;y&#x27;])test_df = test.to_pandas_dataframe()# predict メソッドを使用して推論を実行します。pred = model.predict(test_df)pred.tolist() 以下の通り推論結果を表示できたかと思います。 これらのコードは下記サンプル ノートブック auto-ml-classification-bank-marketing-all-features.ipynb を参考にしておりますので、併せて参照ください。 注意点時系列予測モデルの ForecastingParameters として target_rolling_window_size パラメーターを指定していると、predict の実行が失敗することが確認できています。これは predict メソッドが target_rolling_window_size パラメーターを使用したモデルでの実行をサポートしていないためです。このような場合、以下サンプル ノートブック auto-ml-forecasting-orange-juice-sales.ipynb 、にありますとおり、predict メソッドではなく forecast メソッドの利用をご検討ください。 Web サービスとしてデプロイされたモデルを使用する作成したモデルをローカル、ACI、AKS のいずれかに Web サービスとしてデプロイした場合、要求データを REST エンドポイントに対して送信することで推論結果を得られます。 モデルのデプロイ方法は下記公開情報に纏められています。 Azure Machine Learning を使用してモデルをデプロイする デプロイした Web サービスの呼び出し方は、下記公開情報が参考になります。 Web サービスとしてデプロイされた Azure Machine Learning モデルを使用する デプロイ先がローカル、ACI、AKS それぞれのドキュメントおよびサンプル ノートブックを紹介します。 ローカル docs: Azure Machine Learning コンピューティング インスタンスへのモデルのデプロイ sample: Register model and deploy locally with advanced usages ACI (Azure Container Instance) docs: Azure Container Instances にモデルをデプロイする sample: Register model and deploy as webservice in ACI sample: Deploy Multiple Models as Webservice AKS (Azure Kubernetes Service) docs: Azure Kubernetes Service クラスターにモデルをデプロイする sample: Deploying a web service to Azure Kubernetes Service (AKS) sample: Deploying a web service to Azure Kubernetes Service (AKS) + SSL sample: Deploying a web service to Azure Kubernetes Service (AKS) + GPU そのほか参考となる情報Web サービスの入力データについてWeb サービスを呼び出す Json データは、{“data”: [[ 数値,数値, … ], [ 数値,数値, … ]]} という形式である必要があります。または、辞書形式で {“data”: [{ “列名”:数値, “列名”:数値, … }, { “列名”:数値, “列名”:数値, … }]} としても推論を実行可能です。 以下に、csv ファイルを入力データに変更する方法を紹介させていただきます。まず、下記のコードで推論用データ predictdata.csv を作成します。事前に作成されたデータを使用しても問題ありません。 123456%%writefile predictdata.csvName,age,job,hobby,deposittest1,15,none,car,150000test2,28,office worker,200000test3,35,bank,fishing,3600000test4,40,journalist,1520000 下記コードにて、入力用のデータへ変換します。 1234567891011121314151617181920212223import csvimport jsonjson_list = []# CSV ファイルの読み込みwith open(&#x27;predictdata.csv&#x27;, &#x27;r&#x27;) as f: for row in csv.DictReader(f): json_list.append(row)# JSON ファイルへの書き込みwith open(&#x27;predict.json&#x27;, &#x27;w&#x27;) as f: json.dump(json_list, f, ensure_ascii=False, indent=4)# JSON ファイルのロードwith open(&#x27;predict.json&#x27;, &#x27;r&#x27;) as f: json_output = json.load(f)# 入力用データへの成型data = &#123;&#x27;data&#x27;: [json_output]&#125;# String 形式に変換input_data = json.dumps(data) このとき、input_data 以下の通りです。 1&#x27;&#123;&quot;data&quot;: [[&#123;&quot;Name&quot;: &quot;test1&quot;, &quot;age&quot;: &quot;15&quot;, &quot;job&quot;: &quot;none&quot;, &quot;hobby&quot;: &quot;car&quot;, &quot;deposit&quot;: &quot;150000&quot;&#125;, &#123;&quot;Name&quot;: &quot;test2&quot;, &quot;age&quot;: &quot;28&quot;, &quot;job&quot;: &quot;office worker&quot;, &quot;hobby&quot;: &quot;200000&quot;, &quot;deposit&quot;: null&#125;, &#123;&quot;Name&quot;: &quot;test3&quot;, &quot;age&quot;: &quot;35&quot;, &quot;job&quot;: &quot;bank&quot;, &quot;hobby&quot;: &quot;fishing&quot;, &quot;deposit&quot;: &quot;3600000&quot;&#125;, &#123;&quot;Name&quot;: &quot;test4&quot;, &quot;age&quot;: &quot;40&quot;, &quot;job&quot;: &quot;journalist&quot;, &quot;hobby&quot;: &quot;1520000&quot;, &quot;deposit&quot;: null&#125;]]&#125;&#x27; デザイナーで作成したモデルのデプロイデザイナーでは作成したパイプラインを公開するだけではなく、作成したモデルをデプロイする方法がございます。以下公開情報に纏められておりますので、参考にご参照ください。 スタジオを使用して、デザイナーでトレーニングされたモデルをデプロイする 変更履歴2021/01/13 created by Mochizuki2021/01/21 created by Mochizuki ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"モデル デプロイ","slug":"モデル-デプロイ","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%A2%E3%83%87%E3%83%AB-%E3%83%87%E3%83%97%E3%83%AD%E3%82%A4/"},{"name":"推論","slug":"推論","permalink":"https://jpmlblog.github.io/blog/tags/%E6%8E%A8%E8%AB%96/"}]},{"title":"自動機械学習 (AutoML) の分類タスクのディープ ラーニング有効化について","slug":"AML-deep-learning-for-automl","date":"2020-12-24T03:00:00.000Z","updated":"2022-05-18T08:23:08.906Z","comments":true,"path":"2020/12/24/AML-deep-learning-for-automl/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/12/24/AML-deep-learning-for-automl/","excerpt":"Azure Machine Learning Studio から自動機械学習を実行する際、”ディープ ラーニングの有効化” のチェックを入れた場合の動作について紹介いたします。","text":"Azure Machine Learning Studio から自動機械学習を実行する際、”ディープ ラーニングの有効化” のチェックを入れた場合の動作について紹介いたします。 Azure Machine Learning Studio (https://ml.azure.com/) では、UI ベースで自動機械学習を実行することが出来ます。詳細な手順は以下の公開情報を参照ください。 Azure Machine Learning を使用して自動機械学習モデルを作成、確認、デプロイする 選択できるタスクは、分類、回帰、時系列の 3 つがあります。この時、分類タスクの “ディープ ラーニングの有効化” にチェックを入れることで、テキスト データの特徴付け に有効な BERT または BiLSTM を適用することが可能です。 BERT を適用する場合、コンピューティング クラスターに GPU コンピューティング (例: VM サイズ “STANDARD_NC6”、またはそれ以上の GPU) を使用する必要があります。CPU コンピューティングを使用した場合には、BiLSTM DNN 特徴抽出器が有効になります。詳細は以下の公開情報をご確認ください。 BERT 統合 その他、参考となる公開情報をお纏めします。 How BERT is integrated into Azure automated machine learning AutoML SDK - pretrained_text_dnn_transformer Module AutoML SDK - bilstm_attention_transformer Module GitHub - microsoft/AzureML-BERT GitHub - google-research/bert GitHub - huggingface/transformers 変更履歴2020/12/24 created by Mochizuki ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"Automated Machine Learning","slug":"Automated-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/tags/Automated-Machine-Learning/"}]},{"title":"Azure Functions を使用してパイプラインを定期的に実行する方法について","slug":"AML-scheduled-pipeline","date":"2020-11-30T03:00:00.000Z","updated":"2022-05-18T08:23:09.034Z","comments":true,"path":"2020/11/30/AML-scheduled-pipeline/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/11/30/AML-scheduled-pipeline/","excerpt":"Azure Functions のタイマー トリガーを使用して、Azure Machine Learning で発行されたパイプラインを定期的に実行する方法を紹介します。","text":"Azure Functions のタイマー トリガーを使用して、Azure Machine Learning で発行されたパイプラインを定期的に実行する方法を紹介します。 Azure Machine Learning で発行されたパイプラインを定期的に実行する方法は、以下の 3 つが考えられます。&emsp;A. Azure Machine Learning SDK for Python を使用して機械学習パイプラインのスケジュールを設定する&emsp;B. ロジック アプリから Machine Learning パイプラインの実行をトリガーする&emsp;C. Azure Functions を使用してパイプラインを定期的に実行する C については、詳細な手順を紹介する公開ドキュメントがないため、本記事では C 方法を紹介します。 (参考情報) Azure Machine Learning パイプラインとは パイプラインを発行する Azure でタイマーによってトリガーされる関数を作成する 事前準備本記事では、Visual Studio Code を使用して Azure Functions へデプロイを行います。事前に以下を満たしているかご確認ください。 Azure Machine Learning ワークスペース リソースの作成 Azure Machine Learning ワークスペース リソースへのサービス プリンシパル認証設定(手順参考) 「Authentication in Azure Machine Learning」 の Service Principal Authentication セクション Azure Machine Learning ワークスペース リソースの作成 Visual Studio Code のインストール Azure Functions 拡張機能 のインストール 設定手順Azure Functions のリソースの作成Azure ポータルより Function App リソースを作成します。設定項目は、後述の画像を参照ください。 (参考) Azure Portal で初めての関数を作成する(参考) クイック スタート:Visual Studio Code を使用して Azure で関数を作成する 「基本」情報を設定します。&emsp;設定例:&emsp;&emsp;リソース グループ：任意&emsp;&emsp;関数アプリ名：任意&emsp;&emsp;公開：コード&emsp;&emsp;ランタイム スタック：Python&emsp;&emsp;バージョン：3.8&emsp;&emsp;地域：任意 「ホスティング」情報を設定します。&emsp;設定例:&emsp;&emsp;ストレージ アカウント：既定値&emsp;&emsp;オペレーティング システム：Linux&emsp;&emsp;プランの種類：既定値 Azure Functions プロジェクトの作成Visual Studio Code を起動し、新しいプロジェクトを作成します。 「Create New Project」ボタンをクリックします。 作業用のローカル フォルダーを選択します。 プログラミング言語を選択します。 言語のバージョンを選択します。 「Timer trigger」を選択します。 Function App の名前を付けます。 実行間隔を表す NCRONTAB 式の値を入力します。後で変更可能なので既定のまま進めます。 「Add to workspace」を選択します。 コード ファイルの編集Azure Functions プロジェクトに含まれるコード ファイル (__init__.py、function.json、requirements.txt) を編集します。 __init__.py ServicePrincipalAuthentication 関数の &lt;Tenant_Id&gt;、&lt;Application_Id&gt;、&lt;Client_Secret_Value&gt; の設定は、下記サイトの [Service Principal Authentication] セクションを参照ください。(参考サイト) Authentication in Azure Machine Learning &lt;Subscription_Id&gt;、&lt;ResourceGroup_Name&gt;、&lt;Workspace_Name&gt;、&lt;Pipeline_Id&gt; は、使用する Azure Machine Learning ワークスペース リソースおよびパイプラインの情報を入力ください。&lt;Experiment_Name&gt; はトリガーによって実行した場合の実験名になりますので、任意に指定下さい。 1234567891011121314151617181920212223242526272829303132333435363738394041import datetimeimport loggingimport azure.functions as funcfrom azureml.core.authentication import ServicePrincipalAuthenticationfrom azureml.pipeline.core import PublishedPipelinefrom azureml.core import Workspaceimport requestsSVC_PR_PWD = &quot;&lt;Client_Secret_Value&gt;&quot;def main(mytimer: func.TimerRequest) -&gt; None: utc_timestamp = datetime.datetime.utcnow().replace( tzinfo=datetime.timezone.utc).isoformat() if mytimer.past_due: logging.info(&#x27;The timer is past due!&#x27;) logging.info(&#x27;Python timer trigger function ran at %s&#x27;, utc_timestamp) logging.info(&#x27;Service Principal Authentication&#x27;) svc_pr = ServicePrincipalAuthentication( tenant_id=&quot;&lt;Tenant_Id&gt;&quot;, service_principal_id=&quot;&lt;Application_Id&gt;&quot;, service_principal_password=SVC_PR_PWD) logging.info(&#x27;Get Workspace&#x27;) ws = Workspace(subscription_id=&quot;&lt;Subscription_Id&gt;&quot;, resource_group=&quot;&lt;ResourceGroup_Name&gt;&quot;, workspace_name=&quot;&lt;Workspace_Name&gt;&quot;, auth=svc_pr) logging.info(&#x27;Get Published Pipeline&#x27;) pipeline = PublishedPipeline.get(ws, id=&#x27;&lt;Pipeline_Id&gt;&#x27;) logging.info(&#x27;Run Published Pipeline&#x27;) pipeline_run = pipeline.submit(ws, &#x27;&lt;Experiment_Name&gt;&#x27;) logging.info(&#x27;Waiting result&#x27;) pipeline_run.wait_for_completion(show_output=True) function.jsonshchedule 部分を編集することで実行時刻を変更可能です。指定方法は以下のサイトが参考になります。 (参考サイト) NCRONTAB 式 (参考サイト) NCRONTAB の例 (参考サイト) NCRONTAB タイム ゾーン なお、UTC 指定となりますので、JST で指定する場合には 9 時間を差し引いた時刻を指定ください。以下画像では、毎日 8:30:00 JST に実行する設定としています。 1234567891011&#123; &quot;scriptFile&quot;: &quot;__init__.py&quot;, &quot;bindings&quot;: [ &#123; &quot;name&quot;: &quot;mytimer&quot;, &quot;type&quot;: &quot;timerTrigger&quot;, &quot;direction&quot;: &quot;in&quot;, &quot;schedule&quot;: &quot;0 30 23 * * *&quot; &#125; ]&#125; requirements.txtazureml-core、azureml-pipeline-core、requests を追加します。 12345678# DO NOT include azure-functions-worker in this file# The Python Worker is managed by Azure Functions platform# Manually managing azure-functions-worker may cause unexpected issuesazure-functionsazureml-coreazureml-pipeline-corerequests プロジェクトのデプロイVisual Studio Code より、Azure Functions プロジェクトのデプロイを行います。デプロイ後にコード ファイルの再編集した場合でも、再度デプロイを実行することで変更を反映することが可能です。 Azure アイコンをクリックして、Function App を右クリックして、「Deploy to Function App…」を選択します。 サブスクリプションを選択します。 デプロイ先の Function App リソースを選択します。 「Deploy」ボタンをクリックします。 デプロイが完了したら、画面右下に下記のメッセージが表示されます。 動作確認Azure ポータルより、作成したタイマー トリガーが存在し、有効になっていることを確認します。 Function App の動作を確認します。デプロイ先の Function App リソースに移動して、「関数」ボタンをクリックします。 作成した Function の名前をクリックします。 「モニター」ボタンをクリックして、呼び出しのトレースを確認できます。 上記の「日付」項目をクリックしますと、ログを確認できます。 Machine Learning リソースの実験画面で、Function App の Timer Trigger にトリガーされたパイプラインの実行を確認できます。 Azure Functions を使用してパイプラインを定期的に実行する手順は以上となります。 変更履歴2020/11/30 created by Chao2021/11/30 modified by Mochizuki ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"Azure Functions","slug":"Azure-Functions","permalink":"https://jpmlblog.github.io/blog/tags/Azure-Functions/"}]},{"title":"仮想ネットワーク (Vnet) 上で Azure Machine Learning を使用する方法について","slug":"AML-use-behind-vnet","date":"2020-10-28T03:00:00.000Z","updated":"2022-05-18T08:23:09.064Z","comments":true,"path":"2020/10/28/AML-use-behind-vnet/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/10/28/AML-use-behind-vnet/","excerpt":"Azure Machine Learning を仮想ネットワーク環境で使用する場合に、参考となる情報を列記いたします。また、具体的な作成方法などを本記事にて紹介させていただきます。 仮想ネットワークの分離とプライバシーの概要 仮想ネットワークを使用して Azure Machine Learning ワークスペースをセキュリティで保護する Azure 仮想ネットワークで Azure Machine Learning Studio を使用する Azure Machine Learning ワークスペース用に Azure Private Link を構成する 仮想ネットワークの背後にワークスペースをデプロイする","text":"Azure Machine Learning を仮想ネットワーク環境で使用する場合に、参考となる情報を列記いたします。また、具体的な作成方法などを本記事にて紹介させていただきます。 仮想ネットワークの分離とプライバシーの概要 仮想ネットワークを使用して Azure Machine Learning ワークスペースをセキュリティで保護する Azure 仮想ネットワークで Azure Machine Learning Studio を使用する Azure Machine Learning ワークスペース用に Azure Private Link を構成する 仮想ネットワークの背後にワークスペースをデプロイする 構築方法についてここでは新しく仮想ネットワークを作成し、その配下に各リソースを作成する手順を紹介します。主に以下サイトの手順に従っております。 仮想ネットワークの背後にワークスペースをデプロイする まずは各リソースを作成するリソース グループを作成します。なんらかのリソースの作成に失敗した際に、残存リソースの削除を簡単にするため、新たにリソース グループを作成することをおススメします。リソース基本パラメータおよび実行コマンドは以下の通りです。 項目 パラメータ リージョン eastus (米国東部) リソースグル―プ amlvnetrg 1New-AzResourceGroup -Name amlvnetrg -Location eastus 次に、以下のような構成で各リソースを作成します。指定可能なパラメータは、テンプレート ファイル 「201-machine-learning-advanced/azuredeploy.json」 より参照頂けます。それぞれ用途に応じてカスタイマイズください。 項目 パラメータ 仮想ネットワーク化 リージョン eastus (米国東部) - リソースグル―プ amlvnetrg - 仮想ネットワーク amlvnet - サブネットワーク amlvsubnet - ワークスペース amlvnetworkspace Private Link ストレージ アカウント amlvnetstorage Vnet Key Vault amlvnetkeyvault Vnet Application Insights amlvnetappinsights - (未サポート) Container Registry amlvnetconreg - (クォータ拡張要) 12345678910111213141516New-AzResourceGroupDeployment ` -Name &quot;amlvnetdeployment&quot; ` -ResourceGroupName &quot;amlvnetrg&quot; ` -TemplateUri &quot;https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/201-machine-learning-advanced/azuredeploy.json&quot; ` -location &quot;eastus&quot; ` -vnetOption &quot;new&quot; ` -vnetName &quot;amlvnet&quot; ` -subnetName &quot;amlvsubnet&quot; ` -privateEndpointType &quot;AutoApproval&quot; ` -workspaceName &quot;amlvnetworkspace&quot; ` -storageAccountBehindVNet &quot;true&quot; ` -storageAccountName &quot;amlvnetstorage&quot; ` -keyVaultName &quot;amlvnetkeyvault&quot; ` -keyVaultBehindVNet &quot;true&quot; ` -applicationInsightsName &quot;amlvnetappinsights&quot; ` -containerRegistryName &quot;amlvnetconreg&quot; 注意点 1 :Key Vault リソースは一度削除してから同名で作り直すと soft-delete のエラーが発生します。これは、Key Vault の論理的な削除が働いているためです。「論理的に削除されたキー コンテナーを一覧表示、回復、または消去する」 の手順により、完全に削除することが可能です。 123456New-AzResourceGroupDeployment : xx:xx:xx - Resource Microsoft.KeyVault/vaults &#x27;amlvnetkeyvault&#x27; failed with message &#x27;&#123; &quot;error&quot;: &#123; &quot;code&quot;: &quot;ConflictError&quot;, &quot;message&quot;: &quot;Exist soft deleted vault with the same name. &quot; &#125;&#125;&#x27; 注意点 2 :10/28 現在、Application Insights は仮想ネットワーク背後へのデプロイをサポートしていません。 注意点 3 :Container Registry を仮想ネットワーク背後にデプロイする場合、幾つか条件があります。使用したい場合、まず 「プライベート エンドポイントとプライベート DNS クォータの引き上げ」 に従って、クォータ要求の引き上げをご依頼ください。 次のシナリオでは、場合によっては Microsoft が所有するサブスクリプションでクォータの割り当てを依頼する必要があります。 カスタマーマネージド キー (CMK) を使用する Private Link 対応ワークスペース 仮想ネットワークの背後にあるワークスペースの Azure Container Registry Private Link 対応の Azure Kubernetes Service クラスターのワークスペースへのアタッチ 。 クォータ引き上げ後、上述のコマンドの最後の部分を以下の通り変更することで仮想ネットワーク背後へのデプロイを実行することが可能です。 1234-containerRegistryName &quot;amlvnetconreg&quot; `-containerRegistryBehindVNet &quot;true&quot; `-containerRegistryOption &quot;new&quot; `-containerRegistrySku &quot;Premium&quot; Container Registry を含めて仮想ネットワーク背後への配置した状態は、下記イメージのような状態となります。詳細は 「ワークスペースと関連するリソースをセキュリティで保護する」 を参照ください。 利用上の留意点ワークスペースの Private Link を有効化することで、パブリック インターネット経由のアクセスが制限され、仮想ネットワーク上のリソースからのみアクセスが可能になります。また、Mozilla Firefox を使用した場合には別の問題も報告されておりますので、Microsoft Edge または Google Chrome のご利用をお勧めいたします。 Azure Machine Learning ワークスペース用に Azure Private Link を構成する 重要Azure Private Link は、ワークスペースの削除やコンピューティング リソースの管理などの Azure コントロール プレーン (管理操作) には影響しません。 たとえば、コンピューティング先の作成、更新、削除などです。 これらの操作は、通常どおりパブリック インターネット経由で実行されます。 Azure Machine Learning Studio を使用するなどのデータ プレーン操作、API (公開されたパイプラインを含む)、または SDK では、プライベート エンドポイントが使用されます。 Mozilla Firefox を使用している場合、ワークスペースのプライベート エンドポイントにアクセスしようとしたときに問題が発生することがあります。 この問題は、Mozilla の DNS over HTTPS に関連している可能性があります。 回避策として、Microsoft Edge または Google Chrome を使用することをお勧めします。 パブリック インターネット経由でアクセスした際に表示されるエラーメッセージを以下に紹介します。 Studio アクセスが失敗する場合 NSG を使用してインターネット接続を制限している場合、仮想ネットワーク上のリソースからであっても Azure Machine Learning Studio へのアクセスが出来ない場合があります。下記サイトに記載されております通り、AzureFrontDoor.Frontend のサービス タグ宛の通信を許可する必要がある点についてご留意ください。 Azure 仮想ネットワークで Azure Machine Learning Studio を使用する #VNet 内のリソースから Studio にアクセスする 仮想ネットワーク内のリソース (コンピューティング インスタンスや仮想マシンなど) からスタジオにアクセスする場合は、仮想ネットワークからスタジオへの送信トラフィックを許可する必要があります。 たとえば、ネットワーク セキュリティ グループ (NSG) を使用して送信トラフィックを制限している場合は、 AzureFrontDoor.Frontend の サービス タグ 宛先に規則を追加します。 Home メニュー アクセス時のエラー REQUEST_SEND_ERROR: Your request for data wasn’t sent. Here are some things to try: Check your network and internet connection, make sure a proxy server is not blocking your connection, follow our guidelines if you’re using a private link, and check if you have AdBlock turned on. Notebooks メニュー アクセス時のエラー 403: You are not authorized to access this resource. You are not authorized to access this resource. Request authorization to storage account failed. Storage account might be behind a VNET. Please go to the Compute tab, create a compute instance, and launch Jupyter or Jupyter Lab to use your files and notebooks. Compute メニュー アクセス時のエラー 403: You are not authorized to access this resource. You are not authorized to access this resource. エラーは出力されますが、各コンピューティング リソースの作成、起動、停止、削除などの操作は可能です。必要に応じて、以下サイトを参考にロールベースでのアクセス制御 (RBAC) を実装いただくことをお勧めいたします。 なお、Vnet に配置した Compute Instance のアプリケーション URI (Jupyter および Jupyter Lab のリンク) へのアクセスも、以下のメッセージが表示され失敗します。 User &lt;User Name&gt; does not have access to compute instance &lt;Compute Instance Name&gt;. Only the creator can access a compute instance. Azure Machine Learning ワークスペースへのアクセスの管理 カスタム DNS サーバーを使用している場合仮想ネットワークにカスタム DNS サーバーを設定している場合、DNS 名前解決にプライベート IP アドレスが返されず、アクセスに失敗する可能性があります。下記の情報に従い必要な設定をご検討ください。 カスタム DNS サーバーでワークスペースを使用する方法 ExpressRoute や Azure VPN 経由でアクセスする場合オンプレミスのマシンから ExpressRoute や Azure VPN 経由でワークスペースにアクセスする場合、名前解決で参照先 DNS サーバーの設定に依存してパブリック IP アドレスが返却されてしまい、アクセスが失敗する可能性があります。上述のカスタム DNS サーバーの設定をオンプレミスの DNS サーバーを対象に実施いただくことをご検討ください。 Compute Instance 作成時の留意点ワークスペースで Private Link を有効にしている場合、Compute Instance および Compute Cluster は仮想ネットワーク上にしか作成できなくなります。この時、Compute Instance を作成すると仮想ネットワーク リソースのあるリソース グループ配下に、Load Balancer、Public IP Address、Network Security Group が作成されます。これらのリソースは Compute Instance に紐づいて作成されるため、別リソース グループに移動したり、作成時点で別のリソース グループを指定できない仕様になっております。 リソース グループ単位での管理を行う必要がある場合、仮想ネットワークを Azure Machine Learning ワークスペースと同じリソース グループに作成いただく必要がございますこと、予めご留意願います。 当該仕様変更リクエストを下記フィードバック サイトにて投稿しております。投票数が多いものから追加を検討される傾向にありますので、必要に応じてご投票およびコメントの追加にご協力いただけますと幸いです。 Change resource group for LB, Public IP, and NSG of Compute Instance ※ 順次追加予定です。 変更履歴2020/10/28 created by Mochizuki2020/11/05 modified by Mochizuki2021/04/19 modified by Mochizuki ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"仮想ネットワーク","slug":"仮想ネットワーク","permalink":"https://jpmlblog.github.io/blog/tags/%E4%BB%AE%E6%83%B3%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF/"},{"name":"Private Link","slug":"Private-Link","permalink":"https://jpmlblog.github.io/blog/tags/Private-Link/"}]},{"title":"Azure Machine Learning の名前付け規則について","slug":"AML-dataset-name","date":"2020-10-19T03:00:00.000Z","updated":"2022-05-18T08:23:08.899Z","comments":true,"path":"2020/10/19/AML-dataset-name/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/10/19/AML-dataset-name/","excerpt":"データセットの名前に漢字などの全角文字を使用した場合、登録後に Azure Machine Learning スタジオから参照できなくなる事象が報告されています。Azure Machine Learning の利用における名前付け規則などを踏まえ、現在確認されている事象について紹介いたします。","text":"データセットの名前に漢字などの全角文字を使用した場合、登録後に Azure Machine Learning スタジオから参照できなくなる事象が報告されています。Azure Machine Learning の利用における名前付け規則などを踏まえ、現在確認されている事象について紹介いたします。 名前付け規則についてAzure Machine Learning で使用するリソースの名前付け規則として、下記公開情報をのとおり、ワークスペースのリソースと、これを作成するリソース グループに名前付けの規則がございます。 Azure リソースの名前付け規則と制限事項 #Microsoft.MachineLearningServices Entity Scope 長さ 有効な文字 workspaces&nbsp;&nbsp;&nbsp; resource group&nbsp;&nbsp;&nbsp; 3-33&nbsp;&nbsp;&nbsp; 英数字とハイフン&nbsp;&nbsp;&nbsp; workspaces / computes&nbsp;&nbsp;&nbsp; ワークスペース 2-16&nbsp;&nbsp;&nbsp; 英数字とハイフン&nbsp;&nbsp;&nbsp; また、Azure Machine Learning スタジオ上でコンピューティング リソースを作成する場合には、下記画像のように有効な文字の情報が表示され、名前の検証が行われますので、これに従い名前を指定下さい。 エラー例 1. エラー例 2. エラー例 3. データセットの名前付けで発生する事象についてデータセットを登録する際に指定する名前には、上述のような公開情報や、機械的な名前検証が行われません。しかしながら、UTF-8 の 1 バイト コード以外の文字 (漢字などの全角文字や異なる言語の文字) を使用した場合、登録後に Azure Machine Learning スタジオで参照できなくなるといった現象が報告されています。 例えば、下記の通り全角の “Ｄａｔａｓｅｔ” という名前で登録するとします。 これをクリックすると、以下の通り HTTP 404 エラーが表示されます。 対処方法についてこのデータセットを Azure Machine Learning スタジオ上で登録解除しようとしても、正常に処理が進まず失敗します。この事象は、現在 (2020/10/19) 弊社開発部門にフィードバックを行い調査中となります。 回避策として、Azure Machine Learning の CLI 拡張機能をすることでこれを登録解除することが出来ます。下記公開情報に従い、拡張機能のインストールおよびデータセットの登録解除をお試しください。 Azure Machine Learning の CLI 拡張機能のインストールと使用 実行例:Azure CLI がインストール済みの環境では以下の実行します。 12az extension add -n azure-cli-mlaz extension update -n azure-cli-ml 初回アクセス時には、以下のコマンドでワークスペースにアタッチします。 1az ml folder attach -w &quot;ワークスペース名&quot; -g &quot;リソース グル―プ名&quot; 以下のコマンドでデータセットの登録を解除します。 1az ml dataset unregister -n &quot;データセット名&quot; 変更履歴2020/10/19 created by Mochiszuki ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"名前付け規則","slug":"名前付け規則","permalink":"https://jpmlblog.github.io/blog/tags/%E5%90%8D%E5%89%8D%E4%BB%98%E3%81%91%E8%A6%8F%E5%89%87/"},{"name":"Dataset","slug":"Dataset","permalink":"https://jpmlblog.github.io/blog/tags/Dataset/"}]},{"title":"Azure Machine Learning サービス宛の通信を許可する設定について","slug":"AML-network-allow-settings","date":"2020-10-10T03:00:00.000Z","updated":"2022-05-18T08:23:09.002Z","comments":true,"path":"2020/10/10/AML-network-allow-settings/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/10/10/AML-network-allow-settings/","excerpt":"オンプレミスの環境から Azure Machine Learning のサービスを利用する際、外部ネットワーク宛の通信をファイアウォールやプロキシ サーバー等によって制御している場合に、許可すべきホスト名等の情報をご紹介します。","text":"オンプレミスの環境から Azure Machine Learning のサービスを利用する際、外部ネットワーク宛の通信をファイアウォールやプロキシ サーバー等によって制御している場合に、許可すべきホスト名等の情報をご紹介します。 ホスト名ベースの許可Azure Machine Learning で使用する通信先ホスト名の一覧は以下サイトに一覧化されております。これらのホスト名宛の送信方向の通信を許可するよう設定ください。(2022/1/13 時点) ファイアウォールの内側で Azure Machine Learning のワークスペースを使用する - # Microsoft のホスト *.aznbcontent.net*.azureml.ms*.blob.core.windows.net*.in.applicationinsights.azure.com*.instances.azureml.ms*.instances.azureml.net*.notebooks.azure.net*.queue.core.windows.net*.table.core.windows.net*.vault.azure.net&lt;storage&gt;.blob.core.windows.net&lt;storage&gt;.dfs.core.windows.net&lt;storage&gt;.file.core.windows.netdc.applicationinsights.azure.comdc.applicationinsights.microsoft.comdc.services.visualstudio.comgraph.microsoft.comgraph.windows.netlogin.microsoftonline.commanagement.azure.commcr.microsoft.comml.azure.comviennaglobal.azurecr.io ※ &lt;storage&gt; を、使用している Azure Machine Learning ワークスペースの既定のストレージ アカウント名に置き換えてください。 Python パッケージをインストールして使用する要件がある場合、下記のようなホスト名宛の通信を許可する必要があります。なお、下記はインターネット上のすべての Python リソースに必要なホストの完全な一覧ではなく、最も一般的に使用されているもののみを取り上げています。たとえば、GitHub リポジトリまたはその他のホストにアクセスする必要がある場合は、そのシナリオに必要なホストを特定して追加する必要があることをご留意ください。 ファイアウォールの内側で Azure Machine Learning のワークスペースを使用する - # Python のホスト anaconda.com*.anaconda.com*.anaconda.orgpypi.org*.pytorch.org*.tensorflow.org R パッケージをインストールして使用する要件がある場合、下記のようなホスト名宛の通信を許可する必要があります。こちらも、必要なホストの完全な一覧ではない点についてご留意ください。 ファイアウォールの内側で Azure Machine Learning のワークスペースを使用する - # R のホスト cloud.r-project.org ポート番号の許可HTTPS または HTTP (443 および 80) のプロトコルで通信を行います。上記したホスト名一覧に対し、送信方向のポート番号 443 および 80 宛の通信を許可するよう設定ください。 WebSocket の考慮ネットワーク機器などで WebSocket の通信をブロックしている場合、上述したホスト名一覧について許可いただくことをお勧めいたします。以下のホスト名について WebSocket の通信を許可するよう設定ください。 *.azureml.ms (2021/6/17 削除)*.notebooks.azure.net (2021/6/17 削除)*.experiments.azureml.net (2022/1/13 削除)*.instances.azureml.net*.instances.azureml.ms 今後サービス側機能の変更によって別のホスト名で WebSocket 通信を必須とする場合がございますので、その際には適宜許可を追加頂くことをご検討ください。 (参考情報) コンピューティング クラスターとインスタンス コンピューティング インスタンスの Jupyter 機能を動作させるには、Web ソケット通信が無効になっていないことを確認してください。 お使いのネットワークで、*.instances.azureml.net と *.instances.azureml.ms への websocket 接続が許可されていることを確認してください。 IP アドレスの範囲指定で許可する場合下記サイトに紹介されている IP アドレス一覧を使用して許可する方法につきましては、API で一覧を取得する方法が現時点 (2020/10/10) でプレビュー段階であるなどから、利用をお勧めいたしません。 オンプレミスのサービス タグ 変更履歴2020/10/10 created by Mochizuki2021/06/17 modified by Mochizuki2021/07/13 modified by Mochizuki2022/01/13 modified by Uehara ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"ファイアウォール","slug":"ファイアウォール","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%95%E3%82%A1%E3%82%A4%E3%82%A2%E3%82%A6%E3%82%A9%E3%83%BC%E3%83%AB/"},{"name":"プロキシ","slug":"プロキシ","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%97%E3%83%AD%E3%82%AD%E3%82%B7/"}]},{"title":"Azure Functions を使用してコンピューティング インスタンスを自動停止する方法について","slug":"AML-functions-autostop","date":"2020-09-24T03:00:00.000Z","updated":"2022-05-18T08:23:08.966Z","comments":true,"path":"2020/09/24/AML-functions-autostop/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/09/24/AML-functions-autostop/","excerpt":"Azure Functions のタイマー トリガーを使用して、Azure Machine Learning のコンピューティング インスタンスを自動停止する方法を紹介します。","text":"Azure Functions のタイマー トリガーを使用して、Azure Machine Learning のコンピューティング インスタンスを自動停止する方法を紹介します。 Azure Machine Learning のコンピューティング インスタンスは、一度起動すると停止操作を行わない限り起動し続けます。起動時間に比例して仮想マシンの課金が発生しますので、停止忘れてしまった時の料金が思いのほか大きいこともあります。 本記事では、Azure Functions のタイマー トリガーを使用して、Azure Machine Learning SDK (AzureML SDK) のコードを決まった時刻に実行させることで、コンピューティング インスタンスを自動停止させる方法を紹介します。 (補足)Azure Automation は Azure Machine Learning CLI および Python 3 (Preview 段階) の実行をサポートしていないため、本記事では触れておりません。 (参考情報) チュートリアル:Visual Studio Code を使用して Python でサーバーレスの Azure Functions を作成してデプロイする Azure でタイマーによってトリガーされる関数を作成する 事前準備本記事では、Visual Studio Code を使用して Azure Functions へデプロイを行います。事前に以下を満たしているかご確認ください。 Azure Machine Learning ワークスペース リソースの作成 Azure Machine Learning ワークスペース リソースへのサービス プリンシパル認証設定(手順参考) 「Authentication in Azure Machine Learning」 の Service Principal Authentication セクション Visual Studio Code のインストール Azure Functions 拡張機能 のインストール 設定手順Azure Functions のリソースの作成Azure ポータルより Function App リソースを作成します。設定項目は、後述の画像を参照ください。Visual Studio Code からも作成可能ですが、リソース グループの指定ができないため、本手順では Azure ポータルを使用します。 (参考) Azure Portal で初めての関数を作成する(参考) クイック スタート:Visual Studio Code を使用して Azure で関数を作成する 設定例: リソース グループ名: ※ 任意、本手順では functionsrg 関数アプリ名: ※ 任意、本手順では aml-managecompute 公開: コード ランタイム スタック: Python バージョン: 3.6 地域: ※ 任意、本手順では Japan East を選択 設定例: Strage: ※ 既定のまま使用 オペレーティング システム: Linux プランの種類: 消費量 (サーバーレス) Azure Functions プロジェクトの作成Visual Studio Code を起動し、新しいプロジェクトを作成します。 アクティビティ バーの Azure アイコンを選択、 [Functions] 領域で [Create New Project (新しいプロジェクトの作成)] アイコンを選択します。 「Select the folder that will contain your function project (関数プロジェクトを含めるフォルダを選択してください)」 では Browse を選択し、Functions 専用のフォルダーを指定します。 「Select a language for your function project (関数プロジェクトの言語を選択してください)」 では [Python] を選択します。 「Select a Python alias to create a virtual environment (仮想環境を作成する Python エイリアスを選択してください)」 では Python インタープリターの場所を選択します。場所 (以下画像の py 3.7.5 のようなパス) が表示されない場合、[Skip virtual environment] を選択ください。 「Select a template for your project’s first function (プロジェクトの最初の関数のテンプレートを選択してください)」 では [Timer trigger] を選択します。 「Provide a function name (関数名を指定してください)」 では任意の名前を指定します。本手順では既定値 [TimerTrigger1] を使用します。 「Enter a cron expression … (cron 式を入力してください)」 では、自動停止を実行したい時刻を指定します。後から変更可能なので、既定値のままスキップください。 コード ファイルの編集Azure Functions プロジェクトに含まれるコード ファイル (__init__.py、function.json、requirements.txt) を編集します。 __init__.py ServicePrincipalAuthentication 関数の &lt;Tenant ID&gt;、&lt;Client ID&gt;、&lt;Client Secret&gt; の設定は、下記サイトの [Service Principal Authentication] セクションを参照ください。(参考サイト) Authentication in Azure Machine Learning &lt;Workspace Name&gt;、&lt;Subscription ID&gt;、&lt;Resource Group Name&gt; は、ご利用の Azure Machine Learning ワークスペース リソースの情報を入力ください。 停止したいコンピューティング インスタンス名を指定する場合、&lt;Compute Instance Name&gt; に停止したいコンピューティング インスタンス名を指定した配列 compute_name を定義します。 「type(computes[c]) == ComputeInstance」 部分の “ComputeInstance” を “AmlCompute” に変更することでコンピューティング クラスターを指定することも可能です。(参考サイト) compute Package コンピューティング インスタンスの停止処理は、下記サイトの ComputeInstance クラスの stop 関数を使用します。起動させる場合には、state が “Stopped” という条件で、start 関数を実行するようにします。(参考サイト) ComputeInstance class 1234567891011121314151617181920212223242526272829303132333435363738import datetimeimport loggingimport azure.functions as funcfrom azureml.core.workspace import Workspacefrom azureml.core.compute import ComputeTarget, ComputeInstancefrom azureml.core.compute_target import ComputeTargetExceptionfrom azureml.core.authentication import ServicePrincipalAuthenticationdef main(mytimer: func.TimerRequest) -&gt; None: # サービス プリンシパル認証の設定 svc_pr = ServicePrincipalAuthentication( tenant_id=&quot;&lt;Tenant ID&gt;&quot;, service_principal_id=&quot;&lt;Client ID&gt;&quot;, service_principal_password=&quot;&lt;Client Secret&gt;&quot;) # ワークスペース情報の取得 ws = Workspace.get(name=&quot;&lt;Workspace Name&gt;&quot;, subscription_id=&quot;&lt;Subscription ID&gt;&quot;, resource_group=&quot;&lt;Resource Group Name&gt;&quot;, auth=svc_pr) # ワークスペース内の全てのコンピューティング インスタンス名の取得 computes = ws.compute_targets compute_name = [c for c in computes if type(computes[c]) == ComputeInstance] # 停止したいコンピューティング インスタンス名を指定する場合 # compute_name = [&quot;&lt;Compute Instance Name&gt;&quot;, &quot;&lt;Compute Instance Name&gt;&quot;, ...] # Running 状態のコンピューティング インスタンスを停止実行 for i in compute_name: state = ComputeInstance(ws, i).get_status().state if state == &quot;Running&quot;: ComputeInstance(ws, i).stop(wait_for_completion=False, show_output=False) logging.info(f&quot;&#123;i&#125; state is &#123;state&#125; now. The auto-stop process is executed.&quot;) else: logging.info(f&quot;&#123;i&#125; state is &#123;state&#125; now. The auto-stop process is NOT executed.&quot;) function.jsonshchedule 部分を編集することで実行時刻を変更可能です。指定方法は以下のサイトが参考になります。 (参考サイト) NCRONTAB 式 (参考サイト) NCRONTAB の例 (参考サイト) NCRONTAB タイム ゾーン なお、UTC 指定となりますので、JST で指定する場合には 9 時間を差し引いた時刻を指定ください。以下画像では、毎日 21:25:00 JST に起動する設定としています。 1234567891011&#123; &quot;scriptFile&quot;: &quot;__init__.py&quot;, &quot;bindings&quot;: [ &#123; &quot;name&quot;: &quot;mytimer&quot;, &quot;type&quot;: &quot;timerTrigger&quot;, &quot;direction&quot;: &quot;in&quot;, &quot;schedule&quot;: &quot;0 25 12 * * *&quot; &#125; ]&#125; requirements.txtazureml-core を追加します。 123456# DO NOT include azure-functions-worker in this file# The Python Worker is managed by Azure Functions platform# Manually managing azure-functions-worker may cause unexpected issuesazure-functionsazureml-core プロジェクトのデプロイVisual Studio Code より、Azure Functions プロジェクトのデプロイを行います。デプロイ後にコード ファイルの再編集した場合でも、再度デプロイを実行することで変更を反映することが可能です。 Visual Studio Code の [Functions] 領域より作成した Azure Functions リソースを右クリックし、[Deploy to Function App…] を選択します。 「Select the folder to deploy」 では Browse を選択し、Functions 専用のフォルダーを指定します。 上書き確認の警告メッセージがポップアップしますので、[Deploy] を選択して続行します。 動作確認Azure ポータルより、作成した Function App リソースの [関数] メニューを表示し、タイマー トリガーが存在し、有効になっていることを確認します。 タイマー トリガーのリンクをクリックすると、デプロイした設定や動作履歴を確認することが可能です。下記画像は、[モニター] メニューより 12:24:59 UTC (-&gt; 概ね 21:25:00 JST) にトリガーが実行されていることが確認できます。 (参考) AzureML CLI を使用する場合Azure Machine Learning CLI (AzureML CLI) は Azure CLI への拡張機能です。下記サイトに具体的な使用方法が紹介されております。 Azure Machine Learning の CLI 拡張機能のインストールと使用 関連するコマンドは以下サイトより確認可能です。 az ml computetarget computeinstance 本記事では時刻実行する方法については言及せず、コンピューティング インスタンスの起動停止に関連する操作部分のみ抜粋して以下に紹介します。 1234567891011121314151617# Azure サブスクリプションへの CLI の接続 az login # 拡張機能のインストール az extension add -n azure-cli-ml # 拡張機能の更新 az extension update -n azure-cli-ml # ワークスペースへの接続 az ml folder attach -w &lt;ワークスペース名&gt; -g &lt;リソース グル―プ名&gt; # Compute Instance の起動 az ml computetarget computeinstance start -n &lt;コンピューティング インスタンス名&gt; # Compute Instance の停止 az ml computetarget computeinstance stop -n &lt;コンピューティング インスタンス名&gt; 変更履歴2020/09/24 created by Mochizuki2020/09/28 modified by Mochizuki ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"Azure Functions","slug":"Azure-Functions","permalink":"https://jpmlblog.github.io/blog/tags/Azure-Functions/"}]},{"title":"Azure Machine Learning におけるネットワーク関連エラー発生時の情報採取について","slug":"Collectinfo_AzureConnection","date":"2020-08-31T03:00:00.000Z","updated":"2022-05-18T08:23:09.075Z","comments":true,"path":"2020/08/31/Collectinfo_AzureConnection/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/08/31/Collectinfo_AzureConnection/","excerpt":"Azure Machine Learning サービスのご利用時に、HTTP ステータス コードなどネットワーク関連のエラーが表示される場合があります。問題の調査にはネットワーク関連の情報が必要となります。以下に、汎用的な情報採取手順を紹介します。","text":"Azure Machine Learning サービスのご利用時に、HTTP ステータス コードなどネットワーク関連のエラーが表示される場合があります。問題の調査にはネットワーク関連の情報が必要となります。以下に、汎用的な情報採取手順を紹介します。 対象事象の再現が可能な端末 (OS: Windows 10 の各バージョン) 事前準備こちら から CollectInfo_AzureConnection.txt ファイルをダウンロードします。ローカルに保存後、拡張子を .txt から .bat に変更し、任意の場所に移します。 ※ ダウンロード時に拡張子を .bat に変更して保存すると、ダウンロード自体がブロックされる可能性があります。 ローカルに保存後に拡張子を変更ください。 &lt;実施対象に以下が存在する状態&gt;・ [任意の場所]\\CollectInfo_AzureConnection.bat ファイル 影響ログを採取することで負荷が上がる可能性は考えられますが、基本的に OS リソースや処理への影響はありません。 実行手順(1) 再現確認用マシンに管理者アカウントでログオンします。(2) CollectInfo_AzureConnection.bat ファイルを右クリックし、[管理者として実行] を選択します。 ※ 実行時、Microsoft Defender SmartScreen によって実行確認のメッセージが表示される可能性があります。 [詳細情報] をクリックいただくと実行ボタンが表示されますので、[実行] を選択ください。 (3) “Please enter the number you want to execute. Enter q to quit tool.” メッセージに 1 を入力、リターン キーを押下し、表示に従いメニューに戻ります。 ※ CollectInfo_AzureConnection.bat のコマンド プロンプトは起動したままにしておきます。 (4) Microsoft Edge (Chromium) または Chrome を起動し、問題が再現する操作の直前まで画面を進めます。 ※ (5) ～ (11) の手順は 「トラブルシューティングのためにブラウザー トレースをキャプチャする」 の内容を参考にしています。上記以外のブラウザーを使用する場合、こちらのサイトを参考に実行ください。 (5) F12 キーを押下し、デベロッパー ツールを起動します。(6) [Network]タブを選択し、[Preserve log] を選択します。 (7) [Console] タブを選択し、[Console settings] を選択してから、[Preserve Log] を選択します。[Console settings] をもう一度選択して、設定ペインを閉じます。 (8) [Network] タブを選択し、 [Stop recording network log] と [Clear] を選択します。 (9) [Record network log] を選択して、問題を再現します。 ※ 事象の再現を確認、そのまま十数秒ほど待ちます。 (10) [Stop recording network log] を選択し、 [Export HAR] を選択して任意の場所に .har ファイルを保存します。 (11) Console タブを選択します。いずれかのメッセージを右クリックし、 [Save as…] を選択して、任意の場所に .log ファイルを保存します。 ※ 以下、CollectInfo_AzureConnection.bat のコマンド プロンプトにて再度操作を実施します。 (12) “Please enter the number you want to execute. Enter q to quit tool.” メッセージに 2 を入力、リターン キーを押下し、表示に従いメニューに戻ります。(13) “Please enter the number you want to execute. Enter q to quit tool.” メッセージに 3 を入力、リターン キーを押下し、表示に従いメニューに戻ります。(14) “Please enter the number you want to execute. Enter q to quit tool.” メッセージに q を入力、リターン キーを押下してツールを終了します。(15) 手順 (10) および (11) で保存したファイル (拡張子 .har および .log のファイル) と、デスクトップ上 &lt;YYYYMMDD 形式の年月日&gt;_&lt;ホスト名&gt;_info フォルダーをまとめて ZIP 圧縮し、お問い合わせいただく際にご提供ください。 ※ サポート リクエストに関する参考情報・ Azure サポート要求を作成する・ サポート チケットの作成 本記事は 「jpmlblog について」 の留意事項に準じます。 変更履歴2020/08/31 created by Mochizuki","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"情報採取手順","slug":"情報採取手順","permalink":"https://jpmlblog.github.io/blog/tags/%E6%83%85%E5%A0%B1%E6%8E%A1%E5%8F%96%E6%89%8B%E9%A0%86/"}]},{"title":"Azure Machine Learning ワークスペースの作成が Internet Explorer 11 で失敗する","slug":"AML-IE11","date":"2020-08-31T00:00:00.000Z","updated":"2022-05-18T08:23:08.976Z","comments":true,"path":"2020/08/31/AML-IE11/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/08/31/AML-IE11/","excerpt":"Internet Explorer 11 (IE11) 利用時に発生する現象について紹介します。","text":"Internet Explorer 11 (IE11) 利用時に発生する現象について紹介します。 IE11 関連事例についてAzure ポータルで Azure Machine Learning ワークスペースの作成が失敗するといった報告が複数件寄せられております。この事象は、Azure ポータルを Internet Explorer 11 で開いてリソース作成を行った場合に発生することが確認できております。 (再現時、下記表示のまま状態が遷移しません) また、Azure Machine Learning ポータル (https://ml.azure.com/) の操作においても予期しないエラーが発生するといった報告もございます。これらの事象は、別のブラウザ (Microsoft Edge または Chrome) を使用することで回避できる可能性があります。 Internet Explorer 11 は弊社サービスに限らず幅広い Web サービスで、順次サポート対象外になる予定です。恐れ入りますが、現段階で Microsoft Edge などへの移行をご検討ください。 Microsoft 365 アプリの Internet Explorer 11 のサポート終了と Windows 10 での Microsoft Edge レガシー版のサービス終了 その他のブラウザーの事例についてMozilla Firefox を使用する環境において、ワークスペースのプライベート エンドポイントにアクセスしようとしたときに問題が発生するといった報告がございます。この問題は、Mozilla の DNS over HTTPS に関連している可能性があり、Microsoft Edge および Chrome のご利用をお勧めしております。 Azure Machine Learning ワークスペース用に Azure Private Link を構成する Mozilla Firefox を使用している場合、ワークスペースのプライベート エンドポイントにアクセスしようとしたときに問題が発生することがあります。 この問題は、Mozilla の DNS over HTTPS に関連している可能性があります。 回避策として、Microsoft Edge または Google Chrome を使用することをお勧めします。 また、Microsoft Edge および Chrome のご利用環境においても、Azure Machine Learning ポータルの一部のメニューが表示されなかったり、機能の実行が失敗するなどといった事象が報告されています。こうした事象は古いバージョンのブラウザーを使用していることに起因している可能性があるため、原因の切り分けとして以下の切り分けの実施をご検討ください。 ブラウザーを最新バージョンにアップデートする 変更履歴2020-08-31 created by Mochizuki","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"Internet Explorer 11","slug":"Internet-Explorer-11","permalink":"https://jpmlblog.github.io/blog/tags/Internet-Explorer-11/"}]},{"title":"Azure Machine Learning Studio でモデル登録およびデプロイする場合の留意点について","slug":"AML-register-and-deploy-model","date":"2020-08-25T08:00:00.000Z","updated":"2022-05-18T08:23:09.007Z","comments":true,"path":"2020/08/25/AML-register-and-deploy-model/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/08/25/AML-register-and-deploy-model/","excerpt":"Azure Machine Learning Studio でモデル登録する場合の留意点についてお纏めします。","text":"Azure Machine Learning Studio でモデル登録する場合の留意点についてお纏めします。 Azure Machine Learning Studio (https://ml.azure.com/) のユーザー インターフェイスでは、モデル登録およびデプロイを行うことができます。この時、設定方法が誤っているとモデルのデプロイ操作が長時間完了せず、結果として登録が失敗する場合があります。 本記事では、具体的な例を挙げて手順を詳細させていただきます。 モデルの登録Azure Machine Learning Studio (https://ml.azure.com/) の [アセット] - [モデル] の [+ モデルの登録] をクリックします。 表示された入力項目のうち、* マークのある項目を全て埋めて [登録] ボタンをクリックします。 この時、以下の点に留意ください。 モデル フレームワークを誤って選択するとデプロイに失敗します。不明な場合には、[その他] を選択し、フレーム ワーク名、バージョンは空欄にします。指定するとデプロイが簡略化されますが、指定しなくても登録可能です。 (参考情報) Model class The framework of the registered model. Using the system-supported constants from the Framework class allows for simplified deployment for some popular frameworks. モデルのデプロイAzure Machine Learning Studio (https://ml.azure.com/) の [アセット] - [モデル] より、登録されているモデルをクリックします。 表示された入力項目のうち、* マークのある項目を全て埋めて [登録] ボタンをクリックします。 この時、以下の点に留意ください。 エントリ スクリプト ファイルおよび Conda 依存関係ファイルは下記サイトを参考にご準備ください。 (参考情報) エントリ スクリプトを定義する (参考情報) 推論構成を定義する エントリ スクリプト ファイルのモデル指定に誤りがあったり、Conda 依存関係ファイルが誤っていると、デプロイ操作がエラーの表示なく長時間完了しない場合があります。デプロイ先のリソースにエラーが記録されている場合がありますので、厳密な調査が必要となりましたら、モデルファイル、エントリ スクリプト ファイル、Conda 依存関係ファイルと共にサポート リクエストを発行ください。 (参考) 自動 ML (Automated Machine Learning) のモデルのデプロイ自動 ML の実行結果からモデルをデプロイする場合、エントリ スクリプト ファイルおよび Conda 依存関係ファイルを指定する必要はありません。具体的な操作内容は下記サイトを参照ください。(参考情報) モデルをデプロイする 変更履歴2020/08/25 created by Mochizuki","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"モデル登録","slug":"モデル登録","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%A2%E3%83%87%E3%83%AB%E7%99%BB%E9%8C%B2/"},{"name":"デプロイ","slug":"デプロイ","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%87%E3%83%97%E3%83%AD%E3%82%A4/"}]},{"title":"モデルを仮想ネットワーク上の Azure Container Instances (ACI) にデプロイする方法について","slug":"AML-deploy-aci-vnet","date":"2020-08-18T03:00:00.000Z","updated":"2022-05-18T08:23:08.923Z","comments":true,"path":"2020/08/18/AML-deploy-aci-vnet/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/08/18/AML-deploy-aci-vnet/","excerpt":"モデルを仮想ネットワーク上の ACI にデプロイする方法について紹介します。 Azure Machine Learning に仮想ネットワーク (Azure Virtual Network: VNET) を使用することで、機械学習のライフサイクルをセキュリティで保護することが可能になります。例えば、ACI を仮想ネットワークに置くことで、Web エンドポイントをパブリック インターネットから保護することができます。","text":"モデルを仮想ネットワーク上の ACI にデプロイする方法について紹介します。 Azure Machine Learning に仮想ネットワーク (Azure Virtual Network: VNET) を使用することで、機械学習のライフサイクルをセキュリティで保護することが可能になります。例えば、ACI を仮想ネットワークに置くことで、Web エンドポイントをパブリック インターネットから保護することができます。 Azure Machine Learning を使用して Azure Container Instances (ACI) にモデルを Web サービスとしてデプロイする方法は、以下の公開情報が参考になります。 Azure Container Instances にモデルをデプロイする Azure Kubernetes Service と Azure Container Instances を使用したモデルの Docker デプロイのトラブルシューティング 仮想ネットワーク上の ACI にモデルをデプロイする方法は、以下の公開情報に記載されておりますが、手順が分かりづらいため、後述に具体的な手順を紹介させていただきます。 Azure Container Instances (ACI) を有効にする 仮想ネットワークの作成例新たに仮想ネットワークを作成する際には、以下制限事項 について予めご留意ください。 仮想ネットワークで Azure Container Instances を使用する場合、仮想ネットワークは、Azure Machine Learning ワークスペースと同じリソース グループに含まれている必要があります。 仮想ネットワーク内で Azure Container Instances を使用する場合、ご使用のワークスペースの Azure Container Registry (ACR) もその仮想ネットワーク内に配置することはできません。 「サブネットの委任を追加または削除する - 仮想ネットワークの作成」 の手順に従って仮想ネットワークの作成を進めます。 [基本] タブの設定例です。仮想ネットワークはワークスペースと同じリソースグループに作成します。同じリソースグル―プの既存の仮想ネットワークでも使用可能です。名前、地域は任意です。 [IP アドレス] タブの設定例です。仮想ネットワークの IP アドレス帯は任意で変更可能です。サブネットはそのままで進めます。 [セキュリティ]、[タグ] タブも既定のまま進めると下記の画面に進みます。手順例では、リソースグループ amlrg に amlvnet1 という仮想ネットワークが作成されます。 サブネットの作成例作成した仮想ネットワークにサブネットを作成します。「サブネットの委任を追加または削除する - サブネットを Azure サービスに委任する」 の手順に従って進めます。 サブネットの作成例です。名前、アドレス範囲は任意です。サブネットの委任に Microsoft.ContainerInstance/containerGroups を指定します。 ここまで進めると、amlvnet1 配下に default と amlsubnet1 サブネットが存在し、amlsubnet1 には委任先に Microsoft.ContainerInstance/containerGroups が設定されていることが確認できます。 仮想ネットワークへのモデル デプロイ例SDK を使用して作成する必要があります。AciWebservice.deploy_configuration() 関数の引数 vnet_name、subnet_name に作成した仮想ネットワークとサブネットを指定して deployment_config を作成し、Model.deploy() に指定して実行します。具体的な手順は以下を参照ください。 Model.deploy() の実行には models や inference_config を事前に設定している必要があります。以下に、モデル ファイル model.pkl、Conda 依存関係ファイル myenv.yml、エントリ スクリプト ファイル score.py を基にして、それぞれ設定するコード スニペットを紹介します。 1234567891011from azureml.core import Workspacefrom azureml.core import Environmentfrom azureml.core.model import Modelfrom azureml.core.model import InferenceConfigws = Workspace.from_config()model = Model.register(model_path=&quot;model.pkl&quot;, model_name=&quot;mymodel&quot;, workspace=ws)env = Environment.from_conda_specification(name=&#x27;myenv&#x27;, file_path=&#x27;myenv.yml&#x27;)inference_config = InferenceConfig(entry_script=&quot;score.py&quot;, environment=env) 「Azure Container Instances にモデルをデプロイする - SDK を使用する」 のコードに vnet_name、subnet_name を追加して実行します。以下にコード スニペットを紹介します。 1234567from azureml.core.webservice import AciWebservice, Webservicefrom azureml.core.model import Modeldeployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1, vnet_name = &quot;amlvnet1&quot;, subnet_name = &quot;amlsubnet1&quot;)service = Model.deploy(ws, &quot;aciservice&quot;, [model], inference_config, deployment_config)service.wait_for_deployment(show_output = True) 作成された REST エンドポイントは、Azure Machine Learning ポータルの [エンドポイント] から確認できます。以下画像では REST エンドポイントは http://10.0.1.4/score となっています。 参考: Web サービスの動作確認例Web サービスと同じ仮想ネットワーク上にあるコンピュート インスタンスから Web リクエストを実行する方法を紹介します。まず、こちらのサイト を参照し、ネットワーク セキュリティ グループ (NSG) を作成します。下記画像ではリージョンの指定を省略しています。 作成した NSG を amlvnet1 の default サブネットに設定します。 amlvnet1 の default サブネットに Compute Instance を作成します。 作成したコンピュート インスタンス上で以下のコードを実行します。こちら のサイトの手順が参考になります。 1234567891011121314import requestsimport jsonscoring_uri = &#x27;http://10.0.1.4/score&#x27;data = &#123;&quot;data&quot;: [[ *** モデルに併せてデータを設定ください *** ]] &#125;input_data = json.dumps(rawdata)headers = &#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125;resp = requests.post(scoring_uri, input_data , headers=headers)print(resp.text) 変更履歴2020/08/18 created by Mochizuki2022/03/16 created by Mochizuki","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"Azure Container Instances","slug":"Azure-Container-Instances","permalink":"https://jpmlblog.github.io/blog/tags/Azure-Container-Instances/"},{"name":"仮想ネットワーク","slug":"仮想ネットワーク","permalink":"https://jpmlblog.github.io/blog/tags/%E4%BB%AE%E6%83%B3%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF/"}]},{"title":"Azure Machine Learning のコスト見積もりについて","slug":"AML-estimate-costs","date":"2020-06-18T00:00:00.000Z","updated":"2022-05-18T08:23:08.944Z","comments":true,"path":"2020/06/18/AML-estimate-costs/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/06/18/AML-estimate-costs/","excerpt":"Azure Machine Learning のコスト見積もりについて、参考となる情報を紹介します。","text":"Azure Machine Learning のコスト見積もりについて、参考となる情報を紹介します。 本記事では具体的なコストの見積もり例を紹介します。コストの管理に関する基本的な考え方は、下記サイトの内容を参照ください。 Azure Machine Learning のコストを計画して管理する Azure Machine Learning のコストを管理して最適化する コスト見積もり例についてAzure Machine Learning のワークスペース自体には課金は発生しません。ワークスペースで作成したリソースに課金が発生します。 例えば、開発環境として使用する Azure Machine Learning コンピューティング インスタンスや、トレーニングの実行環境として使用する Azure Machine Learning コンピューティング クラスターは、稼働時間分が課金対象となります。また、作成したモデルをデプロイした場合、デプロイ先のサービスについても比較的大きな課金が発生します。参考に見積もり例を後述に紹介します。 ※ ご利用方法によって試算より誤差が生じる場合がありますので、予めご留意ください。 コンピューティング インスタンス開発環境として Azure Machine Learning コンピューティング インスタンス (東日本リージョン、STANDARD_DS3_V2) を 1 日 10 時間起動し、30 日間使用する場合の月額 注意VM としての料金に加えて、下記 3 つのサービスに対して課金が発生いたします。これらの課金はコンピューティング インスタンスを停止していても継続されます。これらのサブ リソースが作成される理由については、”サブ リソースについて” セクションをご参照ください。 例 (東日本リージョン): スタンダード ロード バランサー (約 2.8 [円/時間]) スタンダード (静的) パブリック IP アドレス (約 0.56 [円/時間]) マネージド ディスク p10 (約 2,539.04 [円/月]※ 30 [日/月] の場合、約 3.5264 [円/時間], 31 [日/月] の場合、約 3.4127 [円/時間]) 参考: Azure Machine Learning コンピューティング インスタンスを作成して管理する コンピューティング インスタンスを停止すると、コンピューティング時間の課金は停止しますが、ディスク、パブリック IP、および Standard Load Balancer に対しては引き続き課金されます。 (VM)45.808 [円/時間] x 10 [時間/日] x 30 [日] = 13742.4 [円] (関連サービス ※ 30 [日/月] の場合)(2.8 + 0.56 + 3.5264 [円/時間]) x 24 [時間/日] x 30 [日] = 4958.208 [円] → 合計 13742.4 + 4958.208 = 18700.608 [円] 参考サイトサポートされている VM シリーズおよびサイズAzure Machine Learning の価格負荷分散 の価格IP アドレス の価格Managed Disks の価格料金計算ツール (+Azure Machine Learning)Linux Virtual Machines の料金 コンピューティング クラスタートレーニング ターゲットとして Azure Machine Learning コンピューティング クラスター (東日本リージョン、STANDARD_DS3_V2) を最小 0 ノード、最大 2 ノードで作成し、2 ノードで 1 日 4 時間、30 日間使用する場合の月額 注意:VM としての料金に加えて、下記 3 つのサービスに対して課金が発生いたします。環境情報を維持しないといけないコンピューティング インスタンスとは異なり、停止している場合 (起動しているノード数が 0 の場合) には割り当てが完全に解除されるため、課金は停止します。これらのサブ リソースが作成される理由については、”サブ リソースについて” セクションをご参照ください。 例 (東日本リージョン): スタンダード ロード バランサー (約 2.8 [円/時間]) スタンダード (静的) パブリック IP アドレス (約 0.56 [円/時間]) マネージド ディスク p10 (約 2,539.04 [円/月]※ 30 [日/月] の場合、約 3.5264 [円/時間], 31 [日/月] の場合、約 3.4127 [円/時間]) (VM)45.808 [円/時間/ノード] x 2 [ノード] x 4 [時間/日] x 30 [日] = 10993.92 [円] (関連サービス ※ 30 [日/月] の場合)(2.8 + 0.56 + 3.5264 [円/時間]) x 4 [時間/日] x 30 [日] = 826.368 [円] → 合計 10993.92 + 826.368 = 11820.288 [円] 参考サイトサポートされている VM シリーズおよびサイズAzure Machine Learning の価格Batch の価格負荷分散 の価格IP アドレス の価格Managed Disks の価格料金計算ツール (+Azure Machine Learning)Linux Virtual Machines の料金 推論クラスター (Azure Kubernetes Service, AKS)推論用クラスターとして Azure Kubernetes Service の仮想マシン (東日本リージョン、STANDARD_DS12_V2) を 3 ノードで作成し、30 日間使用する場合の月額 注意:コア数合計を 12 以上で作成する必要があります。 → 51.408 [円/時間/ノード] x 3 [ノード] x 24 [時間/日] x 30 [日] = 111041.28 [円] 参考サイトAzure Kubernetes Service (AKS) の価格料金計算ツール (+Azure Kubernetes Service)Linux Virtual Machines の料金 Azure Container Instance (ACI)モデルを Azure Container Instance (vCPU 1、メモリ 1 GiB) にデプロイし、30 日間使用する場合の月額 注意:Azure Machine Learning で ACI にモデルをデプロイする場合、指定したコンテナーに加えて azureml-fe-aci (それぞれ vCPU 0.1、メモリ 0.5 GiB) が作成されます。また、vCPU は小数点第一位で切り上げされて計上されます。また、メモリは小数点第二位で切り上げされて計上されます。 (vCPU)0.0015743 [円/秒/vCPU] x 2 [vCPU] x 3600 [秒/時間] x 24 [時間/日] = 272.03904 [円/日]272.03904 [円/日] x 30 [日] = 8161.1712 [円] (メモリ)0.0001721 [円/秒/GiB] x 1.5 [Gib] x 3600 [秒/時間] x 24 [時間/日] = 22.30416 [円/日]22.30416 [円/日] x 30 [日] = 669.1248 [円] → 合計 8161.1712 + 669.1248 = 8830.296 [円] 参考サイトContainer Instances の価格料金計算ツール (+Container Instance) 見積もりが難しいコストについて上記に加えて以下リソースの課金が発生いたします。これらはご利用方法によって金額が大きく異なりますため、試算を含めた見積もりを例示することができません。一般的に上述の料金と比較して数パーセント程度の小さい金額となりますため、一定期間ご利用いただいた後、実際の課金額を基に見積もることをお勧めします。 Azure Container Registry Basic アカウント Azure ブロック BLOB Storage (汎用 v1) Key Vault Application Insights また、ワークスペースやストレージ等を仮想ネットワークに配置する場合、パブリック エンドポイントやプライベート DNS ゾーン、ロード バランサーの料金が追加で発生いたします。固定でかかる費用となりますので、こちらも一定期間ご利用いただい後、実際の課金額を基に見積もることをお勧めします。 仮想ネットワークの分離とプライバシーの概要 サブ リソースについてコンピューティング インスタンスおよびコンピューティング クラスターを作成すると、VM の料金に加えてネットワークに関連したリソースが併せて作成されます。これらは作成されたノードとの通信を維持するために使用され、課金の対象になります。 参考: サブ リソース これらのサブ リソースは、AML ワークスペースで作成される主要なリソースです。 VM: AML ワークスペースのコンピューティング能力を提供します。モデルのデプロイとトレーニングに不可欠な要素です。 ロード バランサー: コンピューティング インスタンスおよびクラスターが停止している場合でもトラフィックを管理するために、コンピューティング インスタンスとコンピューティング クラスターごとにネットワーク ロード バランサーが作成されます。 仮想ネットワーク: これらは、Azure リソースが互いに通信したり、インターネットやその他のオンプレミス ネットワークと通信したりするために役立ちます。 帯域幅: リージョン間のすべてのアウトバウンド データ転送をカプセル化します。 参考: リソースの削除前にコストが発生する可能性がある Azure portal 内で、または Azure CLI を使用して Azure Machine Learning ワークスペースを削除する前、ワークスペース内でアクティブに作業していない場合でも、次のサブ リソースは一般的なコストとして蓄積されます。 後でご自身の Azure Machine Learning ワークスペースに戻る予定がある場合、これらのリソースには引き続きコストが発生する可能性があります。 VM Load Balancer Virtual Network 帯域幅 VM はそれぞれ、実行している時間ごとに課金されます。 コストは VM の仕様によって異なります。 実行中であっても、データセットに対してアクティブに動作していない VM については、ロード バランサー経由で課金されます。 コンピューティング インスタンスごとに、1 日あたり 1 つのロード バランサーに対して請求が発生します。 コンピューティング クラスターの 50 ノードごとに、1 つの Standard ロード バランサーが課金されます。 ロード バランサーあたりの課金額は 1 日あたり約 0.33 ドルです。 停止しているコンピューティング インスタンスとコンピューティング クラスターに対してロード バランサーのコストが発生するのを回避するには、コンピューティング リソースを削除します。 サブスクリプションごと、およびリージョンごとに 1 つの仮想ネットワークが課金されます。 仮想ネットワークは、複数のリージョンまたはサブスクリプションにまたがることはできません。 vNet 設定内でプライベート エンドポイントを設定しても、料金が発生することがあります。 帯域幅は使用量に基づいて課金されます。転送データが多いほど、料金は高くなります。 ワークスペース削除Azure ポータルまたは Azure CLI で Azure Machine Learning ワークスペースを削除した後も、次のリソースは引き続き存在します。これらは削除されるまでコストが発生し続けます。 Azure Container Registry Azure Storage Account Key Vault Application Insights これらのリソースと共にワークスペースを削除するには、SDK を使用します。 1ws.delete(delete_dependent_resources=True) ワークスペースに Azure Kubernetes Service (AKS) を作成する場合、またはワークスペースにコンピューティング リソースをアタッチする場合は、Azure ポータルで個別に削除する必要があります。 参考サイトリソースの削除後にコストが発生する可能性がある関連するリソース サービスの価格に関する問い合わせ各サービスの価格に関するご質問 (Azure Machine Learning で発生する費用の内訳を知りたい、または発生したコストがどのリソースで消費しているか、など) は、弊社課金サポートで承っております。以下の画像を参考に、サポート リクエストを発行いただきお問い合わせください。 見積もりの依頼について貴社ご利用方法における見積もりの回答が必要な場合、営業担当のタスクとして対応させていただいております。下記サイトを参考によりご依頼ください。 Azure 価格について 1 対 1 でのガイダンスを受ける Azure 営業担当者に問い合わせる 変更履歴2020/06/18 created by Mochizuki2020/11/12 modified by Mochizuki2020/11/18 modified by Mochizuki2020/11/27 modified by Mochizuki2021/05/26 modified by Mochizuki2021/06/07 modified by Mochizuki2021/07/20 modified by Mochizuki2021/07/28 modified by Mochizuki2021/10/15 modified by Mochizuki ※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"価格","slug":"価格","permalink":"https://jpmlblog.github.io/blog/tags/%E4%BE%A1%E6%A0%BC/"}]},{"title":"Azure Machine Learning Studio (Classic) ワークスペースを削除できない事象について","slug":"AMLSC-cannot-delete","date":"2020-06-09T03:00:00.000Z","updated":"2022-05-18T08:23:09.017Z","comments":true,"path":"2020/06/09/AMLSC-cannot-delete/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/06/09/AMLSC-cannot-delete/","excerpt":"Azure Machine Learning Studio (Classic) のワークスペース削除後も、課金が継続していたり、ポータルからワークスペースにアクセスできてしまう場合の対処方法をご紹介します。","text":"Azure Machine Learning Studio (Classic) のワークスペース削除後も、課金が継続していたり、ポータルからワークスペースにアクセスできてしまう場合の対処方法をご紹介します。 Azure ポータルから対象のリソースを削除した後、そのリソースで継続して課金が発生しているといったお問い合わせを頂くことがございます。この現象は、リソースの削除時の操作や Azure サービス側の不具合等に起因して発生いたします。 Azure Machine Learning Studio (Classic) ワークスペース リソースにおいても、稀にこの現象が発生することが確認できています。例えば、削除したはずのワークスペースの課金が継続していたり、削除したワークスペースへのアクセスができてしまうといった現象が報告されています。 現在、 Machine Learning Studio (Classic) については Azure ポータルからのリソース削除で、課金を含むワークスペースの情報が完全に削除されるようシステムの改修を検討中です。一方で上記のような事象が実際に発生した場合の対処としては、該当リソースの手動削除を弊社開発部門にリクエストする必要がありますので、以下の手順で情報を採取して弊社サポート窓口までお問い合わせください。 (1) 課金が発生しているワークスペース ID / リソース ID を確認 (2) リソース削除を希望するサポート リクエストを発行 それぞれ具体的な手順を後述にご紹介します。 (1) ワークスペース ID / リソース ID の確認手順課金対象になっているリソースの特定には、ワークスペース ID またはリソース ID が必要になります。どちらか一方の情報にて問題ございません。それぞれ確認方法は下記を参照ください。 ワークスペース ID の確認方法 「Azure Machine Learning Studio (Classic) ワークスペース」 にアクセスし、[Settings] メニューよりワークスペース ID を確認します。 リソース ID の確認方法 「Azure の請求書と毎日の使用状況データをダウンロードまたは表示する」 サイトの 「Azure 請求書 (.pdf) のダウンロード」 セクションの 4. の手順より csv ファイルをダウンロードし、ResourceId (ResourceId) の項目を確認します。 CSV ファイルの以下の列を確認ください。 (2) リソース削除を希望するサポート リクエストを発行「Azure サポート要求を作成する方法」 サイトを参考にサポート リクエストを発行します。具体的な設定項目は下記を参照ください。これら以外はサポート リクエストの指示に従いご入力ください。 [基本] タブの設定 問題の種類やサービス、リソースなどはこちらを参考に設定します。 ※ Azure ポータルの言語設定を English にしている場合には、サービスは [Machine Learning Studio] を選択ください。 [詳細] タブの設定 [詳細] タブの [* 詳細] 欄に、確認したワークスペース ID またはリソース ID を記載します。 上記内容が問題解消に向けた手助けとなりましたら幸いです。 変更履歴2020/06/09 created by Mochizuki","categories":[{"name":"Azure Machine Learning Studio (Classic)","slug":"Azure-Machine-Learning-Studio-Classic","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning-Studio-Classic/"}],"tags":[{"name":"リソース削除","slug":"リソース削除","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E5%89%8A%E9%99%A4/"}]},{"title":"Azure Machine Learning の参考となる公開情報について","slug":"reference-websites","date":"2020-04-22T03:00:00.000Z","updated":"2022-05-18T08:23:09.098Z","comments":true,"path":"2020/04/22/reference-websites/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/04/22/reference-websites/","excerpt":"Azure Machine Learninig のご利用にあたり、参考となる公開情報を紹介します。","text":"Azure Machine Learninig のご利用にあたり、参考となる公開情報を紹介します。 Azure Machine Learning 関連サイトAzure Machine Learning の技術ドキュメント、価格、更新情報など。専用ポータルは こちら (https://ml.azure.com/)。 Azure Machine Learning (概要) Azure Machine Learning のドキュメント Azure Machine Learning デザイナーのアルゴリズムとモジュールのリファレンス Azure Machine Learning のリリース ノート Azure Machine Learning の価格 Azure の更新情報 (?product=machine-learning-service) 過去の Q&amp;A、新規 Q&amp;A、機能改善のフィードバックなど。 (旧) Q&amp;A Q&amp;A feedback forum Stack Overflow Azure Machine Learning Studio (Classic) 関連サイト注意当該サービスは 2024 年 8 月 31 日に廃止されます。Azure Machine Learning への早めの移行をご計画ください。参考情報は こちら。 Azure Machine Learning Studio (Classic) の技術ドキュメント、価格、更新情報など。専用ポータルは こちら (https://studio.azureml.net/)。 Azure Machine Learning Studio (classic) のドキュメント Azure Machine Learning Studio (クラシック): アルゴリズムとモジュールのヘルプ Machine Learning Studio の価格 Azure の更新情報 (?product=machine-learning-studio) 過去の Q&amp;A、新規 Q&amp;A、機能改善のフィードバックなど。 (旧) フォーラム サイト フォーラム サイト feedback forum Stack Overflow 機械学習の前提知識習得向け参考サイト機械学習に関する概要情報、学習用のコンテンツなど。 機械学習とは何ですか? 機械学習アルゴリズム ラーニング パス (?term=機械学習) ラーニング パス (?products=azure-machine-learning) とっても便利! Azure Machine Leaning 初心者向けデータ サイエンス解説ビデオ データ サイエンスが回答する 5 つの質問 データ サイエンス用のデータの準備はお済みですか? データで回答できる質問をする 単純なモデルで回答を予測する 他のユーザーの成果物をコピーしてデータ サイエンスを実行する 導入検討向け参考サイトAzure Machine Learning の導入によるメリットや考慮事項、事例など。 Microsoft の機械学習製品およびテクノロジの比較 Azure Machine Learning と Machine Learning Studio (classic) の違い お客様事例の検索 (?sq=”Azure Machine Learning”) Azure アーキテクチャ (?expanded=azure&amp;products=azure-machine-learning) Azure アーキテクチャ (?terms=Azure%20Machine%20Learning) 開発者向け参考サイトAzure Machine Learning を使用して機械学習を開発するための API リファレンスやサンプルなど。 Azure Machine Learning SDK for Python とは Python notebooks with ML and deep learning examples with Azure Machine Learning 機械学習 REST API リファレンス Azure Machine Learning 用の CLI 拡張機能を使用する Browse code samples 変更履歴2020/04/22 created by Mochizuki2020/06/08 modified by Mochizuki2020/06/18 modified by Mochizuki2020/09/08 modified by Mochizuki2021/01/27 modified by Mochizuki※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 適宜追加更新します。","categories":[{"name":"Azure Machine Learning 全般","slug":"Azure-Machine-Learning-全般","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning-%E5%85%A8%E8%88%AC/"}],"tags":[{"name":"参考情報","slug":"参考情報","permalink":"https://jpmlblog.github.io/blog/tags/%E5%8F%82%E8%80%83%E6%83%85%E5%A0%B1/"}]},{"title":"Azure Machine Learning (AzureML, AML) の FAQ","slug":"FAQ","date":"2020-04-22T01:00:00.000Z","updated":"2022-05-18T08:23:09.085Z","comments":true,"path":"2020/04/22/FAQ/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/04/22/FAQ/","excerpt":"よくあるご質問とその回答をまとめております。併せて 本サイトについて 、 ホームページ および 記事一覧 もご参照いただければ幸いです。","text":"よくあるご質問とその回答をまとめております。併せて 本サイトについて 、 ホームページ および 記事一覧 もご参照いただければ幸いです。 製品を理解するために参考となる公開情報を教えて欲しい回答 別途ブログ記事として掲載しております。以下リンクより参照ください。参考となる公開情報について 価格ページでは利用可能なはずの仮想マシンが使用できない回答 こちら のサイトより、各リージョンで利用可能な VM のサイズをご確認頂けます。ただし、利用にはクォータの拡張が必要な場合があります。 例えば、東日本リージョンで NCsv3 シリーズの VM を専用コアとして使用する場合、既定ではクォータが割り当てられていないため作成できません。以下サイトに従い、クォータの増加を要求ください。クォータの増加を要求 Machine Learning ワークスペースを別のリソース グル―プまたは別のサブスクリプションに移動することは可能か回答 不可能です。参考となる情報を紹介します。Azure Machine Learning ワークスペースとは (#workspace-management) ! 警告Azure Machine Learning ワークスペースを別のサブスクリプションに移動したり、所有するサブスクリプションを新しいテナントに移動したりすることは、サポートされていません。 エラーの原因になります。 セキュリティ要件のため各リソースへのアクセスを制限することは可能か回答 認証やアクセス権の付与、ネットワーク的な隔離、監視など、Azure Machine Learning で利用できるセキュリティ機能について、以下サイトにて纏めております。Azure Machine Learning のエンタープライズ セキュリティ 一部抜粋を紹介します。 ストレージ サービスへのアクセスを制限する 以下サイトに記載の認証方法をサポートしています。 Azure Storage サービスに接続する (#supported-data-storage-service-types) Web サービスへのアクセスを制限する TLS 1.2 の有効化、キーベースまたはトークン ベースの認証を有効化する方法があります。 TLS を使用して Azure Machine Learning による Web サービスをセキュリティで保護する Azure Machine Learning のリソースとワークフローの認証を設定する (#web-service-authentication) 外部ネットワークからのアクセスを制限する 仮想ネットワークや Private Link を使用する方法があります。 仮想ネットワークの分離とプライバシーの概要 Configure Azure Private Link for an Azure Machine Learning workspace 公開情報に記載のない利用方法 (例えば、Azure SQL Server の「ファイアウォールと仮想ネットワーク」機能の使用など) はサポートされておりません。詳細につきましては こちら を参照ください。 機能の説明にある 「プレビュー」 とは何か回答 Azure には、マイクロソフトがお客様のご意見を収集するために提供する、プレビュー版、ベータ版、またはその他のプレリリース版の機能、サービス、ソフトウェア、またはリージョン (以下、「プレビュー」といいます) が含まれる場合があります。以下サイトの使用条件に合意することを条件に、プレビューを使用することができます。 Microsoft Azure プレビューの追加使用条件 「現状有姿のまま」「瑕疵を問わない条件」「提供可能な場合に限り提供しうる形で」提供される サービス レベル契約および限定的保証の対象とはならない カスタマー サポートの対象とならない 随時予告なくプレビューを変更または中止することがある 「一般向け提供製品」でリリースしないことを選択する場合がある プレビューは開発段階のサービス・機能でもあるため、公開中のドキュメントと異なる仕様があったり、メンテナンスに伴い使用できなくなることがあります。以下のようなご質問につきましては、基本的に Azure サポートから回答を提供することが難しいことをご理解ください。 一般サービス提供開始予定 予期しない動作の原因調査 公開情報にない仕様の確認 提供開始となった際には Azure の更新情報 サイトより通知されます。また、Azure ポータルまたは Azure Machine Learning のポータルで通知される場合もあります。 コストの見積もり方を知りたい回答 コストの見積もり例について下記記事に纏めています。 Azure Machine Learning のコスト見積もりについて その他、コスト見積もりの参考となる公開情報を紹介します。 Azure Machine Learning のコストを計画して管理する Azure Machine Learning の価格 料金計算ツール (+Azure Machine Learning) 弊社より見積もりの回答が必要な場合、営業担当のタスクとして対応しております。下記サイトよりご依頼ください。 Azure 営業担当者に問い合わせる コンピューティング インスタンスとコンピューティング クラスターの違いについて回答 下記サイトに情報が纏められております。いずれも Microsoft によって管理されるマネージド クラウドベース ワークステーションであり、Azure ポータルのリソースとしては確認することは出来ません。 Azure Machine Learning のしくみ:アーキテクチャと概念 #コンピューティング コンピューティング インスタンス: コンピューティング インスタンスは、機械学習用にインストールされた複数のツールと環境を含む VM です。 コンピューティング インスタンスの主な用途は、開発ワークステーションです。 セットアップを行うことなく、サンプル ノートブックの実行を開始できます。 コンピューティング インスタンスは、トレーニング ジョブと推論ジョブのコンピューティング先として使用できます。 コンピューティング クラスター: コンピューティング クラスターは、マルチノード スケーリング機能を備えた VM のクラスターです。 コンピューティング クラスターは、大規模なジョブと運用環境のコンピューティング先に適しています。 クラスターは、ジョブが送信されるときに自動的にスケールアップされます。 トレーニング コンピューティング ターゲットとして、または開発/テスト デプロイのために使用します。 コンピューティング インスタンス関連情報: Azure Machine Learning コンピューティング インスタンスとは Azure Machine Learning コンピューティング インスタンスを作成して管理する Azure Machine Learning コンピューティング インスタンスへのモデルのデプロイ コンピューティング クラスター関連情報: Azure Machine Learning でのコンピューティング先とは Azure Machine Learning コンピューティング クラスターの作成 チュートリアル:バッチ スコアリング用の Azure Machine Learning パイプラインを作成する Azure Machine Learning Studio (Classic) と Azure Machine Learning のデザイナー機能はどのような違いがあるか回答 それぞれ GUI ベースで機械学習を行うサービスとなりますが、新・旧という形では分けられておらず、データの移行にも対応していません。具体的な差異は以下サイトに纏められております。 Azure Machine Learning と Machine Learning Studio (classic) の違い リソース名に平仮名や漢字を使用可能か回答 使用可能な文字はありますが、予期せぬエラーが発生しリソース作成が失敗する場合があるため、推奨しません。 リソース グループ名やリソース名には、有効な文字を指定させていただいております。下記情報に従い、リソース グループ名を英数字とハイフンのみを使用して作成ください。 Microsoft.MachineLearningServices Microsoft.MachineLearningServices Entity Scope 長さ 有効な文字 workspaces&nbsp;&nbsp;&nbsp; resource group&nbsp;&nbsp;&nbsp; 3-33&nbsp;&nbsp;&nbsp; 英数字とハイフン。 workspaces / computes&nbsp;&nbsp;&nbsp; ワークスペース&nbsp;&nbsp;&nbsp; 2-16&nbsp;&nbsp;&nbsp; 英数字とハイフン。 コンピューティング インスタンスを自動で停止させたい回答 Azure Functions を使用して、特定の時間に停止させる方法を以下記事にて公開しております。 Azure Functions を使用してコンピューティング インスタンスを自動停止する方法について ※ 適宜追加予定回答 ※ 適宜追加更新します。 変更履歴2020/04/22 created by Mochizuki2020/06/18 modified by Mochizuki2020/08/26 modified by Mochizuki2020/10/12 modified by Mochizuki2020/10/29 modified by Mochizuki※ 本記事は 「jpmlblog について」 の留意事項に準じます。※ 併せて 「ホームページ」 および 「記事一覧」 もご参照いただければ幸いです。","categories":[{"name":"Azure Machine Learning 全般","slug":"Azure-Machine-Learning-全般","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning-%E5%85%A8%E8%88%AC/"}],"tags":[{"name":"FAQ","slug":"FAQ","permalink":"https://jpmlblog.github.io/blog/tags/FAQ/"}]},{"title":"自動機械学習 (AutoML) の同時実行数制限について","slug":"AML-limitation-of-AutoML-concurrency","date":"2020-04-06T03:00:00.000Z","updated":"2022-05-18T08:23:08.980Z","comments":true,"path":"2020/04/06/AML-limitation-of-AutoML-concurrency/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/04/06/AML-limitation-of-AutoML-concurrency/","excerpt":"Microsoft Azure Machine Learning ポータル より Automated Machine Learninig (以降、AutoML と記載) を複数同時実行する際の制限事項について紹介します。","text":"Microsoft Azure Machine Learning ポータル より Automated Machine Learninig (以降、AutoML と記載) を複数同時実行する際の制限事項について紹介します。 AutoML の実行にはワークスペース単位で同時実行できる数に制限が存在します。明確に同時実行が可能な数が設定されているものではなく、AutoML の実行に関連するリソースへの負荷が一定値を上回った場合に実行が制限される動作となります。サービス側内部構造上、主にリソース間のコミュニケーションを中継するネットワーク リソースに負荷が集中する仕組みとなっています。 以下図はトレーニング実行時のデータ フローの例です。Training Compute はサイズ変更が可能ですが、それ以外のデータを処理するリソース (通信経路上のネットワーク リソース等) の処理能力をスケール アップすることができないため、負荷が高まることで応答が遅延またはエラーが返され、処理がストップする場合があります。 現在、リソース間の不要なポーリング等を減らして同時実行数の向上を計るなど対応を検討しています。将来的に 100 程度の同時実行が許容できる見込みです。推奨としては、1 ワークスペース 50 の同時実行を目安に運用をご検討ください。 注意データセンター側の物理的なリソース不足に起因して同時実行が失敗する場合もあります。タイミングによっては許容される同時実行数が少なくなる場合があることをご留意ください。 変更履歴2020/04/06 created by Mochizuki","categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"}],"tags":[{"name":"Automated Machine Learning","slug":"Automated-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/tags/Automated-Machine-Learning/"}]},{"title":"jpmlblog について","slug":"about-jpmlblog","date":"2019-12-31T15:00:00.000Z","updated":"2022-05-18T08:23:08.873Z","comments":true,"path":"2020/01/01/about-jpmlblog/","link":"","permalink":"https://jpmlblog.github.io/blog/2020/01/01/about-jpmlblog/","excerpt":"","text":"日本マイクロソフトの Azure Machine Learning に関するサポート情報のブログです。 公開日2020 年 1 月 1 日より公開いたしました。 活動について製品のサポート メンバーによって運用されております。仕様に関する情報やトラブル シューティングの手順、実装におけるワンポイント アドバイスを公開いたします。 留意事項サイトのコンテンツや情報において、可能な限り正確な情報を掲載し、更新するよう努めております。しかしながら、状況の変化や情報が古くなることにより、必ずしもお客様環境に適用できない情報となる場合がございます。恐れ入りますが、予めご留意くださいますようお願い申し上げます。","categories":[{"name":"Azure Machine Learning 全般","slug":"Azure-Machine-Learning-全般","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning-%E5%85%A8%E8%88%AC/"}],"tags":[{"name":"はじめに","slug":"はじめに","permalink":"https://jpmlblog.github.io/blog/tags/%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB/"}]}],"categories":[{"name":"Azure Machine Learning","slug":"Azure-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning/"},{"name":"Azure Machine Learning Studio (classic)","slug":"Azure-Machine-Learning-Studio-classic","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning-Studio-classic/"},{"name":"Azure Machine Learning Studio (Classic)","slug":"Azure-Machine-Learning-Studio-Classic","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning-Studio-Classic/"},{"name":"Azure Machine Learning 全般","slug":"Azure-Machine-Learning-全般","permalink":"https://jpmlblog.github.io/blog/categories/Azure-Machine-Learning-%E5%85%A8%E8%88%AC/"}],"tags":[{"name":"v2 API","slug":"v2-API","permalink":"https://jpmlblog.github.io/blog/tags/v2-API/"},{"name":"Private Endpoint","slug":"Private-Endpoint","permalink":"https://jpmlblog.github.io/blog/tags/Private-Endpoint/"},{"name":"パイプライン","slug":"パイプライン","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3/"},{"name":"ライフサイクル","slug":"ライフサイクル","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%A9%E3%82%A4%E3%83%95%E3%82%B5%E3%82%A4%E3%82%AF%E3%83%AB/"},{"name":"日本語","slug":"日本語","permalink":"https://jpmlblog.github.io/blog/tags/%E6%97%A5%E6%9C%AC%E8%AA%9E/"},{"name":"リソースグループ","slug":"リソースグループ","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%B0%E3%83%AB%E3%83%BC%E3%83%97/"},{"name":"コンピューティング インスタンス","slug":"コンピューティング-インスタンス","permalink":"https://jpmlblog.github.io/blog/tags/%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0-%E3%82%A4%E3%83%B3%E3%82%B9%E3%82%BF%E3%83%B3%E3%82%B9/"},{"name":"サービス終了","slug":"サービス終了","permalink":"https://jpmlblog.github.io/blog/tags/%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E7%B5%82%E4%BA%86/"},{"name":"Blob コンテナー","slug":"Blob-コンテナー","permalink":"https://jpmlblog.github.io/blog/tags/Blob-%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E3%83%BC/"},{"name":"ファイル共有","slug":"ファイル共有","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%85%B1%E6%9C%89/"},{"name":"Notebook","slug":"Notebook","permalink":"https://jpmlblog.github.io/blog/tags/Notebook/"},{"name":"権限","slug":"権限","permalink":"https://jpmlblog.github.io/blog/tags/%E6%A8%A9%E9%99%90/"},{"name":"モデル デプロイ","slug":"モデル-デプロイ","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%A2%E3%83%87%E3%83%AB-%E3%83%87%E3%83%97%E3%83%AD%E3%82%A4/"},{"name":"推論","slug":"推論","permalink":"https://jpmlblog.github.io/blog/tags/%E6%8E%A8%E8%AB%96/"},{"name":"Automated Machine Learning","slug":"Automated-Machine-Learning","permalink":"https://jpmlblog.github.io/blog/tags/Automated-Machine-Learning/"},{"name":"Azure Functions","slug":"Azure-Functions","permalink":"https://jpmlblog.github.io/blog/tags/Azure-Functions/"},{"name":"仮想ネットワーク","slug":"仮想ネットワーク","permalink":"https://jpmlblog.github.io/blog/tags/%E4%BB%AE%E6%83%B3%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF/"},{"name":"Private Link","slug":"Private-Link","permalink":"https://jpmlblog.github.io/blog/tags/Private-Link/"},{"name":"名前付け規則","slug":"名前付け規則","permalink":"https://jpmlblog.github.io/blog/tags/%E5%90%8D%E5%89%8D%E4%BB%98%E3%81%91%E8%A6%8F%E5%89%87/"},{"name":"Dataset","slug":"Dataset","permalink":"https://jpmlblog.github.io/blog/tags/Dataset/"},{"name":"ファイアウォール","slug":"ファイアウォール","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%95%E3%82%A1%E3%82%A4%E3%82%A2%E3%82%A6%E3%82%A9%E3%83%BC%E3%83%AB/"},{"name":"プロキシ","slug":"プロキシ","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%97%E3%83%AD%E3%82%AD%E3%82%B7/"},{"name":"情報採取手順","slug":"情報採取手順","permalink":"https://jpmlblog.github.io/blog/tags/%E6%83%85%E5%A0%B1%E6%8E%A1%E5%8F%96%E6%89%8B%E9%A0%86/"},{"name":"Internet Explorer 11","slug":"Internet-Explorer-11","permalink":"https://jpmlblog.github.io/blog/tags/Internet-Explorer-11/"},{"name":"モデル登録","slug":"モデル登録","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%A2%E3%83%87%E3%83%AB%E7%99%BB%E9%8C%B2/"},{"name":"デプロイ","slug":"デプロイ","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%87%E3%83%97%E3%83%AD%E3%82%A4/"},{"name":"Azure Container Instances","slug":"Azure-Container-Instances","permalink":"https://jpmlblog.github.io/blog/tags/Azure-Container-Instances/"},{"name":"価格","slug":"価格","permalink":"https://jpmlblog.github.io/blog/tags/%E4%BE%A1%E6%A0%BC/"},{"name":"リソース削除","slug":"リソース削除","permalink":"https://jpmlblog.github.io/blog/tags/%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E5%89%8A%E9%99%A4/"},{"name":"参考情報","slug":"参考情報","permalink":"https://jpmlblog.github.io/blog/tags/%E5%8F%82%E8%80%83%E6%83%85%E5%A0%B1/"},{"name":"FAQ","slug":"FAQ","permalink":"https://jpmlblog.github.io/blog/tags/FAQ/"},{"name":"はじめに","slug":"はじめに","permalink":"https://jpmlblog.github.io/blog/tags/%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB/"}]}